{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from swinTransformer import SwinTransformer\n",
    "from util import PatchEmbedding, PatchMerging, PatchExtract\n",
    "from loadDataset import load_data\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "input_dim = 64\n",
    "input_shape = (input_dim, input_dim, 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = load_data(input_dim)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(min(len(x_train), 25)):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (2, 2)  # 2-by-2 sized patches\n",
    "dropout_rate = 0.01  # Dropout rate\n",
    "num_heads = 8  # Attention heads\n",
    "embed_dim = 64  # Embedding dimension\n",
    "num_mlp = 256  # MLP layer size\n",
    "qkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\n",
    "window_size = 1  # Size of attention window\n",
    "shift_size = 1  # Size of shifting window\n",
    "image_dimension = input_dim  # Initial image size\n",
    "\n",
    "num_patch_x = input_shape[0] // patch_size[0]\n",
    "num_patch_y = input_shape[1] // patch_size[1]\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "validation_split = 0.1\n",
    "weight_decay = 0.0001\n",
    "label_smoothing = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(input_shape)\n",
    "x = layers.RandomCrop(image_dimension, image_dimension)(input)\n",
    "x = layers.RandomFlip(\"horizontal\")(x)\n",
    "x = PatchExtract(patch_size)(x)\n",
    "x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
    "x = SwinTransformer(\n",
    "    dim=embed_dim,\n",
    "    num_patch=(num_patch_x, num_patch_y),\n",
    "    num_heads=num_heads,\n",
    "    window_size=window_size,\n",
    "    shift_size=0,\n",
    "    num_mlp=num_mlp,\n",
    "    qkv_bias=qkv_bias,\n",
    "    dropout_rate=dropout_rate,\n",
    ")(x)\n",
    "x = SwinTransformer(\n",
    "    dim=embed_dim,\n",
    "    num_patch=(num_patch_x, num_patch_y),\n",
    "    num_heads=num_heads,\n",
    "    window_size=window_size,\n",
    "    shift_size=shift_size,\n",
    "    num_mlp=num_mlp,\n",
    "    qkv_bias=qkv_bias,\n",
    "    dropout_rate=dropout_rate,\n",
    ")(x)\n",
    "x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "output = layers.Dense(num_classes, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(input, output)\n",
    "\n",
    "# AdamW -> Adam \n",
    "model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing),\n",
    "    optimizer= Adam(\n",
    "        learning_rate=learning_rate,\n",
    "    ),\n",
    "    metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_split=validation_split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, recall, precision = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {round(loss, 2)}\")\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "print(f\"Test f1_score: {round(2 * (precision * recall) / (precision + recall), 2)}\")\n",
    "print(f\"Test precision: {round(precision, 2)}\")\n",
    "print(f\"Test recall: {round(recall, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"./model/enhanceS_{input_dim}dim_{batch_size}batch_{round(loss, 2)}_{round(accuracy, 2)}.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
