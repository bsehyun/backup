{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CRBL Anomaly Detection - PyTorch Inference\n",
        "\n",
        "이 노트북은 PyTorch로 이식된 CRBL 이상 탐지 모델을 사용한 추론 코드입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import cv2 \n",
        "from pathlib import Path\n",
        "\n",
        "# Import our custom modules\n",
        "from model_pytorch import create_model\n",
        "from loadDataset_generator_pytorch import crop_image, origin_image, TestDataset\n",
        "\n",
        "# Configuration\n",
        "INPUT_DIM = 128\n",
        "INPUT_SHAPE = (3, INPUT_DIM, INPUT_DIM)\n",
        "CROPPED_THRESHOLD = 0.01 \n",
        "FULL_THRESHOLD = 0.5 \n",
        "\n",
        "weight_path = \"./weights/CRBL_250328_pytorch.pth\"\n",
        "test_csv_path = \"./data/csv/valid.csv\"\n",
        "image_path = \"./data/images\"\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class InferenceModel:\n",
        "    \"\"\"Inference wrapper for CRBL model\"\"\"\n",
        "    def __init__(self, model_path, input_shape, device):\n",
        "        self.device = device\n",
        "        self.input_shape = input_shape\n",
        "        \n",
        "        # Load model\n",
        "        self.model = create_model(input_shape=input_shape, num_classes=1)\n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "        \n",
        "        # Define transforms\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        \n",
        "    def preprocess_image(self, image):\n",
        "        \"\"\"Preprocess single image for inference\"\"\"\n",
        "        if isinstance(image, str):\n",
        "            image = cv2.imread(image)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Convert to tensor\n",
        "        if isinstance(image, np.ndarray):\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        # Add batch dimension\n",
        "        image = image.unsqueeze(0)\n",
        "        return image.to(self.device)\n",
        "    \n",
        "    def predict_single(self, image):\n",
        "        \"\"\"Predict anomaly for single image\"\"\"\n",
        "        with torch.no_grad():\n",
        "            image_tensor = self.preprocess_image(image)\n",
        "            output = self.model(image_tensor)\n",
        "            probability = output.squeeze().cpu().item()\n",
        "            return probability\n",
        "    \n",
        "    def predict_batch(self, images):\n",
        "        \"\"\"Predict anomaly for batch of images\"\"\"\n",
        "        with torch.no_grad():\n",
        "            if isinstance(images, list):\n",
        "                # Process list of images\n",
        "                batch_tensors = []\n",
        "                for img in images:\n",
        "                    if isinstance(img, str):\n",
        "                        img = cv2.imread(img)\n",
        "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    batch_tensors.append(self.transform(img))\n",
        "                batch_tensor = torch.stack(batch_tensors).to(self.device)\n",
        "            else:\n",
        "                # Process numpy array batch\n",
        "                batch_tensor = torch.from_numpy(images.transpose(0, 3, 1, 2)).float().to(self.device)\n",
        "            \n",
        "            outputs = self.model(batch_tensor)\n",
        "            probabilities = outputs.squeeze().cpu().numpy()\n",
        "            return probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load inference model\n",
        "print(\"Loading inference model...\")\n",
        "inference_model = InferenceModel(weight_path, INPUT_SHAPE, device)\n",
        "\n",
        "# Load test data\n",
        "print(\"Loading test data...\")\n",
        "X_cropped, y_cropped = crop_image(test_csv_path, image_path, INPUT_DIM)\n",
        "X_original, y_original = origin_image(test_csv_path, image_path, INPUT_DIM)\n",
        "\n",
        "print(f\"Test samples: {len(X_cropped)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test data\n",
        "print(\"Predicting on cropped images...\")\n",
        "predictions_cropped = inference_model.predict_batch(X_cropped)\n",
        "\n",
        "print(\"Predicting on original images...\")\n",
        "predictions_original = inference_model.predict_batch(X_original)\n",
        "\n",
        "# Calculate accuracy\n",
        "pred_binary_cropped = (predictions_cropped > CROPPED_THRESHOLD).astype(int)\n",
        "accuracy_cropped = np.mean(pred_binary_cropped == y_cropped)\n",
        "\n",
        "pred_binary_original = (predictions_original > FULL_THRESHOLD).astype(int)\n",
        "accuracy_original = np.mean(pred_binary_original == y_original)\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"Cropped images - Accuracy: {accuracy_cropped:.4f}\")\n",
        "print(f\"Original images - Accuracy: {accuracy_original:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "fig, axes = plt.subplots(2, min(10, len(X_cropped)), figsize=(20, 6))\n",
        "\n",
        "for i in range(min(10, len(X_cropped))):\n",
        "    # Cropped images\n",
        "    axes[0, i].imshow(X_cropped[i])\n",
        "    axes[0, i].set_title(f'Cropped\\nPred: {predictions_cropped[i]:.3f}\\nTrue: {y_cropped[i]}')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Original images\n",
        "    axes[1, i].imshow(X_original[i])\n",
        "    axes[1, i].set_title(f'Original\\nPred: {predictions_original[i]:.3f}\\nTrue: {y_original[i]}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed results\n",
        "print(\"Detailed Results:\")\n",
        "print(\"Cropped images:\")\n",
        "for i, (pred, true) in enumerate(zip(predictions_cropped, y_cropped)):\n",
        "    print(f\"  Sample {i}: Prediction={pred:.4f}, True={true}, Correct={pred_binary_cropped[i]==true}\")\n",
        "\n",
        "print(\"\\nOriginal images:\")\n",
        "for i, (pred, true) in enumerate(zip(predictions_original, y_original)):\n",
        "    print(f\"  Sample {i}: Prediction={pred:.4f}, True={true}, Correct={pred_binary_original[i]==true}\")\n",
        "\n",
        "print(\"\\nInference completed successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
