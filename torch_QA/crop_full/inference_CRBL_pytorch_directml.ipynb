{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CRBL Anomaly Detection - PyTorch Inference with DirectML (Crop & Full Models)\n",
        "\n",
        "이 노트북은 PyTorch로 이식된 CRBL 이상 탐지 모델을 사용한 추론 코드입니다.\n",
        "DirectML을 사용하여 Windows AMD GPU를 지원하며, crop 모델과 full 모델을 모두 사용할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import cv2 \n",
        "from pathlib import Path\n",
        "\n",
        "# Import our custom modules\n",
        "from model_pytorch_dual_directml import (\n",
        "    create_crop_model, create_full_model, create_model, get_device\n",
        ")\n",
        "from loadDataset_generator_pytorch import crop_image, origin_image, TestDataset\n",
        "\n",
        "# Configuration\n",
        "INPUT_DIM = 128\n",
        "INPUT_SHAPE = (3, INPUT_DIM, INPUT_DIM)\n",
        "CROPPED_THRESHOLD = 0.01 \n",
        "FULL_THRESHOLD = 0.5 \n",
        "\n",
        "# Model paths\n",
        "crop_weight_path = \"./weights/CRBL_250328_pytorch_directml_crop.pth\"\n",
        "full_weight_path = \"./weights/CRBL_250328_pytorch_directml_full.pth\"\n",
        "test_csv_path = \"./data/csv/valid.csv\"\n",
        "image_path = \"./data/images\"\n",
        "\n",
        "# Set device (DirectML > CUDA > CPU)\n",
        "device = get_device()\n",
        "\n",
        "# Model type selection\n",
        "MODEL_TYPE = \"crop\"  # \"crop\" or \"full\"\n",
        "weight_path = crop_weight_path if MODEL_TYPE == \"crop\" else full_weight_path\n",
        "\n",
        "print(f\"Using {MODEL_TYPE} model for inference with DirectML...\")\n",
        "print(f\"Model path: {weight_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class InferenceModel:\n",
        "    \"\"\"Inference wrapper for CRBL model with DirectML support and crop/full models\"\"\"\n",
        "    def __init__(self, model_path, input_shape, device, model_type=\"crop\"):\n",
        "        self.device = device\n",
        "        self.input_shape = input_shape\n",
        "        self.model_type = model_type\n",
        "        \n",
        "        # Load model based on type\n",
        "        if model_type == \"crop\":\n",
        "            self.model = create_crop_model(input_shape=input_shape, num_classes=1)\n",
        "        elif model_type == \"full\":\n",
        "            self.model = create_full_model(input_shape=input_shape, num_classes=1)\n",
        "        else:\n",
        "            raise ValueError(\"model_type must be 'crop' or 'full'\")\n",
        "            \n",
        "        self.model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        self.model.to(device)\n",
        "        self.model.eval()\n",
        "        \n",
        "        # Define transforms\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        \n",
        "        print(f\"Loaded {model_type} model successfully with DirectML\")\n",
        "        \n",
        "    def preprocess_image(self, image):\n",
        "        \"\"\"Preprocess single image for inference\"\"\"\n",
        "        if isinstance(image, str):\n",
        "            image = cv2.imread(image)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Convert to tensor\n",
        "        if isinstance(image, np.ndarray):\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        # Add batch dimension\n",
        "        image = image.unsqueeze(0)\n",
        "        return image.to(self.device)\n",
        "    \n",
        "    def predict_single(self, image):\n",
        "        \"\"\"Predict anomaly for single image\"\"\"\n",
        "        with torch.no_grad():\n",
        "            image_tensor = self.preprocess_image(image)\n",
        "            output = self.model(image_tensor)\n",
        "            probability = output.squeeze().cpu().item()\n",
        "            return probability\n",
        "    \n",
        "    def predict_batch(self, images):\n",
        "        \"\"\"Predict anomaly for batch of images\"\"\"\n",
        "        with torch.no_grad():\n",
        "            if isinstance(images, list):\n",
        "                # Process list of images\n",
        "                batch_tensors = []\n",
        "                for img in images:\n",
        "                    if isinstance(img, str):\n",
        "                        img = cv2.imread(img)\n",
        "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    batch_tensors.append(self.transform(img))\n",
        "                batch_tensor = torch.stack(batch_tensors).to(self.device)\n",
        "            else:\n",
        "                # Process numpy array batch\n",
        "                batch_tensor = torch.from_numpy(images.transpose(0, 3, 1, 2)).float().to(self.device)\n",
        "            \n",
        "            outputs = self.model(batch_tensor)\n",
        "            probabilities = outputs.squeeze().cpu().numpy()\n",
        "            return probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load inference model\n",
        "print(\"Loading inference model...\")\n",
        "inference_model = InferenceModel(weight_path, INPUT_SHAPE, device, MODEL_TYPE)\n",
        "\n",
        "# Load test data\n",
        "print(\"Loading test data...\")\n",
        "X_cropped, y_cropped = crop_image(test_csv_path, image_path, INPUT_DIM)\n",
        "X_original, y_original = origin_image(test_csv_path, image_path, INPUT_DIM)\n",
        "\n",
        "print(f\"Test samples: {len(X_cropped)}\")\n",
        "\n",
        "# Select appropriate data based on model type\n",
        "if MODEL_TYPE == \"crop\":\n",
        "    X_test, y_test = X_cropped, y_cropped\n",
        "    threshold = CROPPED_THRESHOLD\n",
        "    print(\"Using cropped images for inference\")\n",
        "else:\n",
        "    X_test, y_test = X_original, y_original\n",
        "    threshold = FULL_THRESHOLD\n",
        "    print(\"Using original images for inference\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test data\n",
        "print(f\"Predicting on {MODEL_TYPE} images...\")\n",
        "predictions = inference_model.predict_batch(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "pred_binary = (predictions > threshold).astype(int)\n",
        "accuracy = np.mean(pred_binary == y_test)\n",
        "\n",
        "print(f\"\\nResults for {MODEL_TYPE} model:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Threshold used: {threshold}\")\n",
        "\n",
        "# Also test on both types for comparison\n",
        "print(\"\\nTesting on both image types for comparison:\")\n",
        "predictions_cropped = inference_model.predict_batch(X_cropped)\n",
        "predictions_original = inference_model.predict_batch(X_original)\n",
        "\n",
        "pred_binary_cropped = (predictions_cropped > CROPPED_THRESHOLD).astype(int)\n",
        "accuracy_cropped = np.mean(pred_binary_cropped == y_cropped)\n",
        "\n",
        "pred_binary_original = (predictions_original > FULL_THRESHOLD).astype(int)\n",
        "accuracy_original = np.mean(pred_binary_original == y_original)\n",
        "\n",
        "print(f\"Cropped images - Accuracy: {accuracy_cropped:.4f}\")\n",
        "print(f\"Original images - Accuracy: {accuracy_original:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "fig, axes = plt.subplots(2, min(10, len(X_cropped)), figsize=(20, 6))\n",
        "\n",
        "for i in range(min(10, len(X_cropped))):\n",
        "    # Cropped images\n",
        "    axes[0, i].imshow(X_cropped[i])\n",
        "    axes[0, i].set_title(f'Cropped\\nPred: {predictions_cropped[i]:.3f}\\nTrue: {y_cropped[i]}')\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Original images\n",
        "    axes[1, i].imshow(X_original[i])\n",
        "    axes[1, i].set_title(f'Original\\nPred: {predictions_original[i]:.3f}\\nTrue: {y_original[i]}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.suptitle(f'{MODEL_TYPE.title()} Model Predictions (DirectML)', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed results\n",
        "print(f\"Detailed Results for {MODEL_TYPE} model:\")\n",
        "print(f\"Primary test ({MODEL_TYPE} images):\")\n",
        "for i, (pred, true) in enumerate(zip(predictions, y_test)):\n",
        "    print(f\"  Sample {i}: Prediction={pred:.4f}, True={true}, Correct={pred_binary[i]==true}\")\n",
        "\n",
        "print(\"\\nComparison results:\")\n",
        "print(\"Cropped images:\")\n",
        "for i, (pred, true) in enumerate(zip(predictions_cropped, y_cropped)):\n",
        "    print(f\"  Sample {i}: Prediction={pred:.4f}, True={true}, Correct={pred_binary_cropped[i]==true}\")\n",
        "\n",
        "print(\"\\nOriginal images:\")\n",
        "for i, (pred, true) in enumerate(zip(predictions_original, y_original)):\n",
        "    print(f\"  Sample {i}: Prediction={pred:.4f}, True={true}, Correct={pred_binary_original[i]==true}\")\n",
        "\n",
        "print(f\"\\nInference completed successfully for {MODEL_TYPE} model with DirectML!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
