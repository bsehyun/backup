import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.interpolate import interp1d
from scipy.stats import pearsonr, spearmanr
from scipy.fft import fft, fftfreq
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.decomposition import PCA
from dtaidistance import dtw
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['figure.figsize'] = (14, 8)
sns.set_style("whitegrid")

# ============================================================================
# 1. ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´ í•„ìš”)
# ============================================================================
def generate_sample_data(n_batches=50):
    """
    ìƒ˜í”Œ ACN ì •ì œ ë°°ì¹˜ ë°ì´í„° ìƒì„±
    ê° ë°°ì¹˜: phase1, phase2, phase3ì˜ ì‹œê³„ì—´ ë°ì´í„°
    """
    data = []
    
    for batch_id in range(n_batches):
        # ê° phaseì˜ ê¸¸ì´ (ê°€ë³€)
        len_p1 = np.random.randint(80, 150)
        len_p2 = np.random.randint(100, 200)
        len_p3 = np.random.randint(60, 120)
        
        # ê¸°ë³¸ ê¶¤ì ì— ë…¸ì´ì¦ˆ ì¶”ê°€
        noise_scale = np.random.uniform(0.3, 1.5)
        golden_factor = np.random.uniform(0.6, 1.4)  # ê³ ìˆ˜ìœ¨ ê·¼ì ‘ë„
        
        # Phase 1: ìƒìŠ¹ ì¶”ì„¸
        p1 = 20 + 30 * np.linspace(0, 1, len_p1) + np.random.normal(0, noise_scale, len_p1)
        
        # Phase 2: ì˜¤ì‹¤ë ˆì´ì…˜ í¬í•¨ (golden cycleì€ ìž‘ì€ ì˜¤ì‹¤ë ˆì´ì…˜)
        t2 = np.linspace(0, 4*np.pi, len_p2)
        p2 = 50 + 15*np.sin(t2) * golden_factor + np.random.normal(0, noise_scale, len_p2)
        
        # Phase 3: í•˜ê°• ì¶”ì„¸
        p3 = 65 - 20 * np.linspace(0, 1, len_p3) + np.random.normal(0, noise_scale, len_p3)
        
        # ìˆ˜ìœ¨ ê³„ì‚° (ì˜¤ì‹¤ë ˆì´ì…˜ ì•ˆì •ì„±, ê¸°ìš¸ê¸° ë“±ì— ë”°ë¼)
        osc_quality = 1.0 / (1.0 + np.std(np.diff(p2)))  # ìž‘ì€ ì˜¤ì‹¤ë ˆì´ì…˜ì´ ì¢‹ìŒ
        trend_quality = np.abs(np.mean(np.diff(p1))) / 10.0  # ì ì ˆí•œ ìƒìŠ¹ ê¸°ìš¸ê¸°
        yield_val = 70 + 20 * osc_quality + 10 * trend_quality + np.random.normal(0, 3)
        yield_val = np.clip(yield_val, 50, 95)
        
        batch_data = {
            'batch_id': f'B{batch_id:03d}',
            'phase1': p1.tolist(),
            'phase2': p2.tolist(),
            'phase3': p3.tolist(),
            'yield': yield_val
        }
        data.append(batch_data)
    
    return data

# ============================================================================
# 2. ì‹œê°„ ì •ê·œí™” ë° ë³´ê°„
# ============================================================================
def normalize_timeseries(phase_data, target_length=200):
    """
    ê°€ë³€ ê¸¸ì´ì˜ phaseë¥¼ ê³ ì • ê¸¸ì´ë¡œ ì •ê·œí™”
    """
    original_length = len(phase_data)
    x_old = np.linspace(0, 1, original_length)
    x_new = np.linspace(0, 1, target_length)
    
    f = interp1d(x_old, phase_data, kind='cubic', fill_value='extrapolate')
    normalized = f(x_new)
    
    return normalized

def prepare_normalized_data(raw_data):
    """
    ëª¨ë“  ë°°ì¹˜ì˜ phaseë¥¼ ì •ê·œí™”ëœ í˜•íƒœë¡œ ë³€í™˜
    """
    normalized_data = []
    
    for batch in raw_data:
        normalized_batch = {
            'batch_id': batch['batch_id'],
            'phase1': normalize_timeseries(batch['phase1']),
            'phase2': normalize_timeseries(batch['phase2']),
            'phase3': normalize_timeseries(batch['phase3']),
            'yield': batch['yield']
        }
        normalized_data.append(normalized_batch)
    
    return normalized_data

# ============================================================================
# 3. íŠ¹ì„± ì¶”ì¶œ (Feature Extraction)
# ============================================================================
def extract_features(phase_data, phase_name):
    """
    ë‹¨ì¼ phaseì—ì„œ ë‹¤ì–‘í•œ íŠ¹ì„± ì¶”ì¶œ
    """
    features = {}
    
    # ê¸°ë³¸ í†µê³„ëŸ‰
    features[f'{phase_name}_mean'] = np.mean(phase_data)
    features[f'{phase_name}_std'] = np.std(phase_data)
    features[f'{phase_name}_min'] = np.min(phase_data)
    features[f'{phase_name}_max'] = np.max(phase_data)
    features[f'{phase_name}_range'] = np.max(phase_data) - np.min(phase_data)
    
    # íŠ¸ë Œë“œ (1ì°¨ ë° 2ì°¨ ë¯¸ë¶„)
    diff1 = np.diff(phase_data)
    diff2 = np.diff(diff1)
    
    features[f'{phase_name}_trend'] = np.mean(diff1)
    features[f'{phase_name}_trend_std'] = np.std(diff1)
    features[f'{phase_name}_acceleration'] = np.mean(diff2)
    
    # ì˜¤ì‹¤ë ˆì´ì…˜ ë¶„ì„
    features[f'{phase_name}_oscillation_amp'] = np.std(diff1)
    
    # FFTë¥¼ í†µí•œ ì£¼íŒŒìˆ˜ ë¶„ì„
    fft_vals = np.abs(fft(phase_data - np.mean(phase_data)))
    freqs = fftfreq(len(phase_data))
    dominant_freq_idx = np.argmax(fft_vals[1:len(fft_vals)//2]) + 1
    features[f'{phase_name}_dominant_freq'] = freqs[dominant_freq_idx]
    features[f'{phase_name}_spectral_power'] = fft_vals[dominant_freq_idx]
    
    # ê·¹ê°’ ë¶„ì„
    peaks = np.where((phase_data[1:-1] > phase_data[:-2]) & 
                     (phase_data[1:-1] > phase_data[2:]))[0] + 1
    valleys = np.where((phase_data[1:-1] < phase_data[:-2]) & 
                       (phase_data[1:-1] < phase_data[2:]))[0] + 1
    
    features[f'{phase_name}_n_peaks'] = len(peaks)
    features[f'{phase_name}_n_valleys'] = len(valleys)
    
    if len(peaks) > 0:
        features[f'{phase_name}_peak_amp'] = np.mean(phase_data[peaks])
        features[f'{phase_name}_peak_variance'] = np.var(phase_data[peaks])
    else:
        features[f'{phase_name}_peak_amp'] = 0
        features[f'{phase_name}_peak_variance'] = 0
    
    # ê³¡ë¥  (Curvature)
    if len(diff2) > 0:
        curvature = np.abs(diff2) / (1 + np.abs(diff1[:-1])**2)**1.5
        features[f'{phase_name}_curvature_mean'] = np.mean(curvature)
    else:
        features[f'{phase_name}_curvature_mean'] = 0
    
    # ì—ë„ˆì§€
    features[f'{phase_name}_energy'] = np.sum(phase_data**2)
    
    return features

def extract_all_features(normalized_data):
    """
    ëª¨ë“  ë°°ì¹˜ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
    """
    feature_list = []
    batch_ids = []
    yields = []
    
    for batch in normalized_data:
        batch_features = {}
        
        for phase_name in ['phase1', 'phase2', 'phase3']:
            phase_features = extract_features(batch[phase_name], phase_name)
            batch_features.update(phase_features)
        
        feature_list.append(batch_features)
        batch_ids.append(batch['batch_id'])
        yields.append(batch['yield'])
    
    features_df = pd.DataFrame(feature_list)
    features_df['batch_id'] = batch_ids
    features_df['yield'] = yields
    
    return features_df

# ============================================================================
# 4. DTW ê±°ë¦¬ ê³„ì‚°
# ============================================================================
def calculate_dtw_distance(phase1, phase2):
    """
    ë‘ ì‹œê³„ì—´ ê°„ì˜ DTW ê±°ë¦¬ ê³„ì‚°
    """
    try:
        return dtw.distance(phase1, phase2)
    except:
        return np.inf

def calculate_batch_similarity_matrix(normalized_data):
    """
    ëª¨ë“  ë°°ì¹˜ ìŒ ê°„ì˜ DTW ê¸°ë°˜ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
    """
    n_batches = len(normalized_data)
    similarity_matrix = np.zeros((n_batches, n_batches))
    
    for i in range(n_batches):
        for j in range(i, n_batches):
            # Phaseë³„ ê±°ë¦¬ì˜ ê°€ì¤‘ í‰ê· 
            d1 = calculate_dtw_distance(normalized_data[i]['phase1'], 
                                        normalized_data[j]['phase1'])
            d2 = calculate_dtw_distance(normalized_data[i]['phase2'], 
                                        normalized_data[j]['phase2'])
            d3 = calculate_dtw_distance(normalized_data[i]['phase3'], 
                                        normalized_data[j]['phase3'])
            
            distance = (d1 + d2 + d3) / 3.0
            similarity_matrix[i, j] = distance
            similarity_matrix[j, i] = distance
    
    return similarity_matrix

# ============================================================================
# 5. ìƒê´€ì„± ë¶„ì„ ë° íŠ¹ì„± ì„ íƒ
# ============================================================================
def analyze_feature_correlation(features_df):
    """
    íŠ¹ì„±ê³¼ ìˆ˜ìœ¨ ê°„ì˜ ìƒê´€ì„± ë¶„ì„
    """
    correlation_results = []
    
    for col in features_df.columns:
        if col not in ['batch_id', 'yield']:
            pearson_corr, p_val = pearsonr(features_df[col], features_df['yield'])
            spearman_corr, sp_val = spearmanr(features_df[col], features_df['yield'])
            
            correlation_results.append({
                'feature': col,
                'pearson_corr': pearson_corr,
                'spearman_corr': spearman_corr,
                'importance': np.abs(pearson_corr)
            })
    
    corr_df = pd.DataFrame(correlation_results)
    corr_df = corr_df.sort_values('importance', ascending=False)
    
    return corr_df

def select_top_features(features_df, corr_df, top_n=15):
    """
    ìƒê´€ì„± ê¸°ë°˜ ìƒìœ„ íŠ¹ì„± ì„ íƒ
    """
    top_features = corr_df.head(top_n)['feature'].tolist()
    return features_df[top_features + ['batch_id', 'yield']]

# ============================================================================
# 6. í´ëŸ¬ìŠ¤í„°ë§ ë° Golden Cycle ì •ì˜
# ============================================================================
def identify_golden_clusters(features_df, top_features, n_clusters=4):
    """
    íŠ¹ì„± ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ê³ ìˆ˜ìœ¨ ê·¸ë£¹ ì‹ë³„
    """
    X = features_df[top_features].values
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    features_df['cluster'] = kmeans.fit_predict(X_scaled)
    
    # í´ëŸ¬ìŠ¤í„°ë³„ ìˆ˜ìœ¨ í†µê³„
    cluster_stats = features_df.groupby('cluster')['yield'].agg([
        'mean', 'std', 'count'
    ]).sort_values('mean', ascending=False)
    
    print("\n=== í´ëŸ¬ìŠ¤í„°ë³„ ìˆ˜ìœ¨ í†µê³„ ===")
    print(cluster_stats)
    
    # ìµœê³  ìˆ˜ìœ¨ í´ëŸ¬ìŠ¤í„° (Golden Cluster)
    golden_cluster = cluster_stats.index[0]
    
    return features_df, golden_cluster, cluster_stats

def calculate_golden_trajectory(normalized_data, golden_cluster_batches):
    """
    ê³ ìˆ˜ìœ¨ ë°°ì¹˜ë“¤ì˜ í‰ê·  ê¶¤ì  ê³„ì‚°
    """
    golden_traj = {
        'phase1': np.zeros(200),
        'phase2': np.zeros(200),
        'phase3': np.zeros(200)
    }
    
    for phase_name in golden_traj.keys():
        phase_data = np.array([b[phase_name] for b in golden_cluster_batches])
        golden_traj[phase_name] = np.mean(phase_data, axis=0)
    
    return golden_traj

# ============================================================================
# 7. ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
# ============================================================================
def build_yield_prediction_model(features_df, top_features):
    """
    Random Forestë¥¼ ì´ìš©í•œ ìˆ˜ìœ¨ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•
    """
    X = features_df[top_features].values
    y = features_df['yield'].values
    
    model = RandomForestRegressor(n_estimators=100, random_state=42, 
                                   max_depth=10, min_samples_split=5)
    model.fit(X, y)
    
    y_pred = model.predict(X)
    r2 = r2_score(y, y_pred)
    mae = mean_absolute_error(y, y_pred)
    
    print(f"\n=== ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ===")
    print(f"RÂ² Score: {r2:.4f}")
    print(f"MAE: {mae:.4f}")
    
    # íŠ¹ì„± ì¤‘ìš”ë„
    feature_importance = pd.DataFrame({
        'feature': top_features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    return model, feature_importance

# ============================================================================
# 8. ì‹œê°í™”
# ============================================================================
def plot_normalized_batches(normalized_data, golden_cluster_mask, title="Batch Trajectories"):
    """
    ëª¨ë“  ë°°ì¹˜ì˜ ì •ê·œí™”ëœ ê¶¤ì  ì‹œê°í™”
    """
    fig, axes = plt.subplots(1, 3, figsize=(16, 5))
    phases = ['phase1', 'phase2', 'phase3']
    
    for idx, phase_name in enumerate(phases):
        ax = axes[idx]
        
        for i, batch in enumerate(normalized_data):
            color = 'red' if golden_cluster_mask[i] else 'lightgray'
            alpha = 0.8 if golden_cluster_mask[i] else 0.3
            ax.plot(batch[phase_name], color=color, alpha=alpha, linewidth=1.5)
        
        ax.set_title(f'{phase_name.upper()} - ì •ê·œí™”ëœ ê¶¤ì ')
        ax.set_xlabel('ì •ê·œí™”ëœ ì‹œê°„')
        ax.set_ylabel('ì¸¡ì •ê°’')
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def plot_golden_vs_others(normalized_data, golden_cluster_mask, normalized_data_full):
    """
    Golden cluster vs Others ë¹„êµ
    """
    fig, axes = plt.subplots(2, 3, figsize=(16, 8))
    phases = ['phase1', 'phase2', 'phase3']
    
    for col, phase_name in enumerate(phases):
        golden_data = np.array([normalized_data[i][phase_name] 
                               for i in range(len(normalized_data)) 
                               if golden_cluster_mask[i]])
        other_data = np.array([normalized_data[i][phase_name] 
                              for i in range(len(normalized_data)) 
                              if not golden_cluster_mask[i]])
        
        # í‰ê·  ë° ì‹ ë¢°ë„ êµ¬ê°„
        golden_mean = np.mean(golden_data, axis=0)
        golden_std = np.std(golden_data, axis=0)
        
        other_mean = np.mean(other_data, axis=0) if len(other_data) > 0 else np.zeros(200)
        other_std = np.std(other_data, axis=0) if len(other_data) > 0 else np.zeros(200)
        
        time_axis = np.linspace(0, 1, 200)
        
        # ìƒë‹¨: í‰ê·  ê¶¤ì 
        ax = axes[0, col]
        ax.fill_between(time_axis, golden_mean - golden_std, golden_mean + golden_std,
                        alpha=0.3, color='red', label='Golden (Â±1 std)')
        ax.plot(time_axis, golden_mean, 'r-', linewidth=2, label='Golden Mean')
        
        if len(other_data) > 0:
            ax.fill_between(time_axis, other_mean - other_std, other_mean + other_std,
                           alpha=0.2, color='blue', label='Others (Â±1 std)')
            ax.plot(time_axis, other_mean, 'b--', linewidth=2, label='Others Mean')
        
        ax.set_title(f'{phase_name.upper()} - í‰ê·  ê¶¤ì  ë¹„êµ')
        ax.set_xlabel('ì •ê·œí™”ëœ ì‹œê°„')
        ax.set_ylabel('ì¸¡ì •ê°’')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # í•˜ë‹¨: í‘œì¤€íŽ¸ì°¨ ë¹„êµ
        ax = axes[1, col]
        ax.plot(time_axis, golden_std, 'r-', linewidth=2, label='Golden Std')
        if len(other_data) > 0:
            ax.plot(time_axis, other_std, 'b--', linewidth=2, label='Others Std')
        ax.set_title(f'{phase_name.upper()} - ì•ˆì •ì„± (í‘œì¤€íŽ¸ì°¨)')
        ax.set_xlabel('ì •ê·œí™”ëœ ì‹œê°„')
        ax.set_ylabel('í‘œì¤€íŽ¸ì°¨')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def plot_correlation_heatmap(features_df, top_features):
    """
    ìƒìœ„ íŠ¹ì„±ë“¤ ê°„ì˜ ìƒê´€ì„± ížˆíŠ¸ë§µ
    """
    corr_matrix = features_df[top_features].corr()
    
    fig, ax = plt.subplots(figsize=(12, 10))
    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
                center=0, square=True, ax=ax, cbar_kws={'label': 'ìƒê´€ê³„ìˆ˜'})
    ax.set_title('ìƒìœ„ íŠ¹ì„±ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„')
    plt.tight_layout()
    
    return fig

def plot_feature_importance(feature_importance, top_n=15):
    """
    íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”
    """
    fig, ax = plt.subplots(figsize=(10, 8))
    top_features = feature_importance.head(top_n)
    
    ax.barh(range(len(top_features)), top_features['importance'].values, color='steelblue')
    ax.set_yticks(range(len(top_features)))
    ax.set_yticklabels(top_features['feature'].values)
    ax.set_xlabel('ì¤‘ìš”ë„ (Feature Importance)')
    ax.set_title('ìˆ˜ìœ¨ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” íŠ¹ì„± ì¤‘ìš”ë„')
    plt.tight_layout()
    
    return fig

def plot_golden_trajectory(golden_trajectory, normalized_data, golden_mask):
    """
    Golden Cycleì˜ ìµœì  ì¶”ì´ë¥¼ ìƒì„¸í•˜ê²Œ ì‹œê°í™”
    """
    fig = plt.figure(figsize=(18, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)
    
    phases = ['phase1', 'phase2', 'phase3']
    phase_names = ['Phase 1\n(ìƒìŠ¹ ì¶”ì„¸)', 'Phase 2\n(ì˜¤ì‹¤ë ˆì´ì…˜)', 'Phase 3\n(í•˜ê°• ì¶”ì„¸)']
    
    time_axis = np.linspace(0, 1, 200)
    
    # ====== ìƒë‹¨: ê° phaseë³„ ìƒì„¸ ë¶„ì„ ======
    for col, (phase_name, phase_label) in enumerate(zip(phases, phase_names)):
        ax = fig.add_subplot(gs[0, col])
        
        # Golden cluster ë°ì´í„°
        golden_data = np.array([normalized_data[i][phase_name] 
                               for i in range(len(normalized_data)) 
                               if golden_mask.iloc[i]])
        
        # ëª¨ë“  ë°°ì¹˜
        all_data = np.array([normalized_data[i][phase_name] 
                            for i in range(len(normalized_data))])
        
        # ê°œë³„ ë°°ì¹˜ (íˆ¬ëª…ë„)
        for trajectory in all_data:
            ax.plot(time_axis, trajectory, 'gray', alpha=0.15, linewidth=0.8)
        
        # Golden ë°°ì¹˜ë“¤
        for trajectory in golden_data:
            ax.plot(time_axis, trajectory, 'lightcoral', alpha=0.4, linewidth=1.2)
        
        # Golden í‰ê·  (êµµì€ ì„ )
        ax.plot(time_axis, golden_trajectory[phase_name], 'r-', linewidth=3.5, 
                label='Golden Mean', zorder=10)
        
        # ì‹ ë¢°ë„ êµ¬ê°„
        golden_std = np.std(golden_data, axis=0)
        ax.fill_between(time_axis, 
                        golden_trajectory[phase_name] - golden_std,
                        golden_trajectory[phase_name] + golden_std,
                        alpha=0.25, color='red', label='Â±1 Std Dev', zorder=5)
        
        ax.set_title(phase_label, fontsize=12, fontweight='bold')
        ax.set_xlabel('ì •ê·œí™”ëœ ì‹œê°„ ì§„í–‰ë„')
        ax.set_ylabel('ì¸¡ì •ê°’')
        ax.grid(True, alpha=0.3)
        ax.legend(loc='best', fontsize=9)
    
    # ====== ì¤‘ë‹¨: ë¯¸ë¶„ ë¶„ì„ (íŠ¸ë Œë“œ/ì†ë„) ======
    for col, phase_name in enumerate(phases):
        ax = fig.add_subplot(gs[1, col])
        
        golden_data = np.array([normalized_data[i][phase_name] 
                               for i in range(len(normalized_data)) 
                               if golden_mask.iloc[i]])
        
        # 1ì°¨ ë¯¸ë¶„ (ë³€í™” ì†ë„)
        golden_diff = np.diff(golden_trajectory[phase_name])
        golden_diff_std = np.std([np.diff(traj) for traj in golden_data], axis=0)
        
        time_axis_diff = np.linspace(0, 1, len(golden_diff))
        
        # ë°°ê²½ (ëª¨ë“  ë°°ì¹˜)
        for trajectory in golden_data:
            ax.plot(time_axis_diff, np.diff(trajectory), 'lightgray', 
                   alpha=0.3, linewidth=0.8)
        
        # Golden í‰ê·  ë³€í™”ìœ¨
        ax.plot(time_axis_diff, golden_diff, 'darkred', linewidth=2.5, label='Mean Trend')
        
        # ì‹ ë¢°ë„ êµ¬ê°„
        ax.fill_between(time_axis_diff, 
                        golden_diff - golden_diff_std,
                        golden_diff + golden_diff_std,
                        alpha=0.3, color='red', label='Trend Â±1 Std')
        
        ax.axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=1)
        ax.set_title(f'{phases[col].upper()}\në³€í™” ì†ë„ (1st Derivative)', 
                    fontsize=11, fontweight='bold')
        ax.set_xlabel('ì •ê·œí™”ëœ ì‹œê°„ ì§„í–‰ë„')
        ax.set_ylabel('ë³€í™”ìœ¨ (dX/dt)')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=8)
    
    # ====== í•˜ë‹¨: 2ì°¨ ë¯¸ë¶„ (ê°€ì†ë„/ê³¡ë¥ ) ======
    for col, phase_name in enumerate(phases):
        ax = fig.add_subplot(gs[2, col])
        
        # 2ì°¨ ë¯¸ë¶„ (ê°€ì†ë„)
        golden_diff2 = np.diff(np.diff(golden_trajectory[phase_name]))
        
        time_axis_diff2 = np.linspace(0, 1, len(golden_diff2))
        
        # Golden ê°€ì†ë„
        ax.plot(time_axis_diff2, golden_diff2, 'darkred', linewidth=2.5, 
               marker='o', markersize=4, label='Acceleration')
        
        # 0 ê¸°ì¤€ì„ 
        ax.axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=1)
        
        # ì–‘ìˆ˜/ìŒìˆ˜ ì˜ì—­ ê°•ì¡°
        ax.fill_between(time_axis_diff2, 0, golden_diff2, 
                        where=(golden_diff2 >= 0), alpha=0.3, color='green', 
                        label='Positive (Speeding up)')
        ax.fill_between(time_axis_diff2, 0, golden_diff2, 
                        where=(golden_diff2 < 0), alpha=0.3, color='red', 
                        label='Negative (Slowing down)')
        
        ax.set_title(f'{phases[col].upper()}\nê°€ì†ë„ (2nd Derivative)', 
                    fontsize=11, fontweight='bold')
        ax.set_xlabel('ì •ê·œí™”ëœ ì‹œê°„ ì§„í–‰ë„')
        ax.set_ylabel('ê°€ì†ë„ (dÂ²X/dtÂ²)')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=8)
    
    fig.suptitle('Golden Cycle ìµœì  ì¶”ì´ ë¶„ì„\nê°œë³„ ê¶¤ì  | íŠ¸ë Œë“œ | ê°€ì†ë„', 
                fontsize=14, fontweight='bold', y=0.995)
    
    return fig

def plot_golden_trajectory_combined(golden_trajectory, normalized_data, golden_mask, 
                                    features_df_clustered, golden_cluster):
    """
    Golden Cycleì˜ ì „ì²´ í”„ë¡œíŒŒì¼ì„ í•œ ë²ˆì— í‘œì‹œ
    """
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    
    phases = ['phase1', 'phase2', 'phase3']
    phase_colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
    
    # ====== ì¢Œìƒ: ì „ì²´ í”„ë¡œì„¸ìŠ¤ ê¶¤ì  ======
    ax = axes[0, 0]
    
    time_axis = np.linspace(0, 1, 200)
    total_time = np.concatenate([
        time_axis,
        1 + time_axis,
        2 + time_axis
    ])
    
    golden_data = np.array([normalized_data[i]['phase1'] 
                           for i in range(len(normalized_data)) 
                           if golden_mask.iloc[i]])
    
    for trajectory in golden_data:
        full_traj = np.concatenate([
            normalized_data[np.where(golden_mask)[0][0]]['phase1'],
            normalized_data[np.where(golden_mask)[0][0]]['phase2'],
            normalized_data[np.where(golden_mask)[0][0]]['phase3']
        ])
        ax.plot(total_time, full_traj, 'lightgray', alpha=0.2, linewidth=0.8)
    
    # Golden í‰ê·  ì „ì²´ ê¶¤ì 
    full_golden = np.concatenate([
        golden_trajectory['phase1'],
        golden_trajectory['phase2'],
        golden_trajectory['phase3']
    ])
    
    ax.plot(total_time, full_golden, 'r-', linewidth=3, label='Golden Trajectory', zorder=10)
    
    # Phase êµ¬ë¶„ì„ 
    for phase_sep in [1, 2]:
        ax.axvline(x=phase_sep, color='black', linestyle='--', alpha=0.5, linewidth=2)
    
    ax.set_xticks([0.5, 1.5, 2.5])
    ax.set_xticklabels(['Phase 1\nìƒìŠ¹', 'Phase 2\nì˜¤ì‹¤ë ˆì´ì…˜', 'Phase 3\ní•˜ê°•'])
    ax.set_title('ì „ì²´ í”„ë¡œì„¸ìŠ¤ Golden Trajectory', fontsize=12, fontweight='bold')
    ax.set_ylabel('ì¸¡ì •ê°’')
    ax.grid(True, alpha=0.3)
    ax.legend(fontsize=10)
    
    # ====== ìš°ìƒ: Phaseë³„ íŠ¹ì„± ë¹„êµ ======
    ax = axes[0, 1]
    
    phase_stats = []
    for i, phase_name in enumerate(phases):
        golden_phase = np.array([normalized_data[j][phase_name] 
                                for j in range(len(normalized_data)) 
                                if golden_mask.iloc[j]])
        
        phase_stats.append({
            'phase': f'Phase {i+1}',
            'mean': np.mean(golden_trajectory[phase_name]),
            'std': np.std(golden_phase),
            'range': np.max(golden_trajectory[phase_name]) - np.min(golden_trajectory[phase_name]),
            'trend': np.mean(np.diff(golden_trajectory[phase_name]))
        })
    
    stat_names = ['mean', 'std', 'range', 'trend']
    x = np.arange(len(phases))
    width = 0.2
    
    for idx, stat_name in enumerate(stat_names):
        values = [stat['std' if stat_name == 'std' else stat_name] for stat in phase_stats]
        ax.bar(x + idx*width, values, width, label=stat_name.upper())
    
    ax.set_xlabel('Phase')
    ax.set_ylabel('ê°’')
    ax.set_title('Phaseë³„ íŠ¹ì„± ë¹„êµ', fontsize=12, fontweight='bold')
    ax.set_xticks(x + width * 1.5)
    ax.set_xticklabels([s['phase'] for s in phase_stats])
    ax.legend()
    ax.grid(True, alpha=0.3, axis='y')
    
    # ====== ì¢Œí•˜: ìˆ˜ìœ¨ ë¶„í¬ ======
    ax = axes[1, 0]
    
    golden_yields = features_df_clustered[golden_mask]['yield'].values
    other_yields = features_df_clustered[~golden_mask]['yield'].values
    
    ax.hist(golden_yields, bins=8, alpha=0.6, color='red', label=f'Golden (Î¼={golden_yields.mean():.1f}%)', edgecolor='darkred')
    ax.hist(other_yields, bins=8, alpha=0.6, color='blue', label=f'Others (Î¼={other_yields.mean():.1f}%)', edgecolor='darkblue')
    
    ax.axvline(golden_yields.mean(), color='red', linestyle='--', linewidth=2)
    ax.axvline(other_yields.mean(), color='blue', linestyle='--', linewidth=2)
    
    ax.set_xlabel('ìˆ˜ìœ¨ (%)')
    ax.set_ylabel('ë°°ì¹˜ ìˆ˜')
    ax.set_title('Golden vs Others ìˆ˜ìœ¨ ë¶„í¬', fontsize=12, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3, axis='y')
    
    # ====== ìš°í•˜: í†µê³„ ì •ë³´ ======
    ax = axes[1, 1]
    ax.axis('off')
    
    golden_count = golden_mask.sum()
    golden_yield_mean = golden_yields.mean()
    golden_yield_std = golden_yields.std()
    
    stats_text = f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘       GOLDEN CYCLE ìµœì  ì¡°ê±´           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ðŸ“Š ë°°ì¹˜ í†µê³„
    â”œâ”€ Golden Batch ìˆ˜: {golden_count}ê°œ
    â”œâ”€ ì´ Batch ìˆ˜: {len(normalized_data)}ê°œ
    â””â”€ Golden ë¹„ìœ¨: {golden_count/len(normalized_data)*100:.1f}%
    
    ðŸŽ¯ ìˆ˜ìœ¨ ì„±ëŠ¥
    â”œâ”€ í‰ê·  ìˆ˜ìœ¨: {golden_yield_mean:.2f}%
    â”œâ”€ í‘œì¤€íŽ¸ì°¨: {golden_yield_std:.2f}%
    â”œâ”€ ìµœì†Œê°’: {golden_yields.min():.2f}%
    â””â”€ ìµœëŒ€ê°’: {golden_yields.max():.2f}%
    
    ðŸ“ˆ Phaseë³„ íŠ¹ì„±
    â”œâ”€ Phase 1 ë²”ìœ„: {np.max(golden_trajectory['phase1']) - np.min(golden_trajectory['phase1']):.2f}
    â”œâ”€ Phase 2 í‰ê· : {np.mean(golden_trajectory['phase2']):.2f}
    â””â”€ Phase 3 ê¸°ìš¸ê¸°: {np.mean(np.diff(golden_trajectory['phase3'])):.4f}
    
    âœ“ ê¶Œìž¥ ìš´ì „ ì¡°ê±´
    â”œâ”€ Phase 1: ì•ˆì •ì  ìƒìŠ¹ ì¶”ì´ ìœ ì§€
    â”œâ”€ Phase 2: ì œì–´ëœ ì˜¤ì‹¤ë ˆì´ì…˜ (í‘œì¤€íŽ¸ì°¨ ìµœì†Œí™”)
    â””â”€ Phase 3: ì¼ì •í•œ ì†ë„ë¡œ ê°ì†Œ
    """
    
    ax.text(0.05, 0.95, stats_text, transform=ax.transAxes,
           fontsize=10, verticalalignment='top', fontfamily='monospace',
           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    fig.suptitle('Golden Cycle ìµœì  ì¡°ê±´ ì¢…í•© ë¶„ì„', 
                fontsize=14, fontweight='bold', y=0.995)
    
    plt.tight_layout()
    return fig

# ============================================================================
# 9. ë©”ì¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸
# ============================================================================
def main():
    print("=" * 70)
    print("ACN ì •ì œ ë°°ì¹˜ - Golden Cycle ë¶„ì„")
    print("=" * 70)
    
    # 1. ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ë¡œ êµì²´)
    print("\n[1ë‹¨ê³„] ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    raw_data = generate_sample_data(n_batches=50)
    normalized_data = prepare_normalized_data(raw_data)
    
    # 2. íŠ¹ì„± ì¶”ì¶œ
    print("[2ë‹¨ê³„] íŠ¹ì„± ì¶”ì¶œ ì¤‘...")
    features_df = extract_all_features(normalized_data)
    print(f"ì¶”ì¶œëœ íŠ¹ì„± ìˆ˜: {len(features_df.columns) - 2}")
    
    # 3. ìƒê´€ì„± ë¶„ì„
    print("[3ë‹¨ê³„] ìƒê´€ì„± ë¶„ì„ ì¤‘...")
    corr_df = analyze_feature_correlation(features_df)
    top_features = select_top_features(features_df, corr_df, top_n=15)
    
    print("\n=== ìƒìœ„ ìƒê´€ íŠ¹ì„± (ìˆ˜ìœ¨ê³¼ì˜ ê´€ê³„) ===")
    print(corr_df.head(15)[['feature', 'pearson_corr']])
    
    # 4. í´ëŸ¬ìŠ¤í„°ë§
    print("\n[4ë‹¨ê³„] í´ëŸ¬ìŠ¤í„°ë§ ë° Golden Cycle ì‹ë³„ ì¤‘...")
    features_df_clustered, golden_cluster, cluster_stats = identify_golden_clusters(
        features_df, top_features['feature'].tolist())
    
    # Golden cluster ë°°ì¹˜ ì¶”ì¶œ
    golden_mask = features_df_clustered['cluster'] == golden_cluster
    golden_batch_ids = features_df_clustered[golden_mask]['batch_id'].tolist()
    golden_cluster_batches = [b for b in normalized_data 
                              if b['batch_id'].split('_')[0] + '...' not in golden_batch_ids]
    
    # ì‹¤ì œ ë§¤ì¹­ì„ ìœ„í•´ ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ìž¬êµ¬ì„±
    golden_cluster_batches = [normalized_data[i] for i in range(len(normalized_data)) 
                              if golden_mask.iloc[i]]
    
    golden_trajectory = calculate_golden_trajectory(normalized_data, golden_cluster_batches)
    
    print(f"\nGolden Cluster ID: {golden_cluster}")
    print(f"Golden Batch ìˆ˜: {len(golden_cluster_batches)}")
    print(f"í‰ê·  ìˆ˜ìœ¨: {features_df_clustered[golden_mask]['yield'].mean():.2f}%")
    
    # 5. ì˜ˆì¸¡ ëª¨ë¸
    print("\n[5ë‹¨ê³„] ìˆ˜ìœ¨ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶• ì¤‘...")
    model, feature_importance = build_yield_prediction_model(
        features_df_clustered, top_features['feature'].tolist())
    
    print("\n=== ìƒìœ„ ì¤‘ìš” íŠ¹ì„± ===")
    print(feature_importance.head(10))
    
    # 6. ì‹œê°í™”
    print("\n[6ë‹¨ê³„] ì‹œê°í™” ìƒì„± ì¤‘...")
    
    fig1 = plot_normalized_batches(normalized_data, golden_mask.values)
    fig1.suptitle('ì •ê·œí™”ëœ ë°°ì¹˜ ê¶¤ì  (ë¹¨ê°•: Golden Cycle)', y=1.02)
    
    fig2 = plot_golden_vs_others(normalized_data, golden_mask.values, normalized_data)
    
    fig3 = plot_correlation_heatmap(features_df_clustered, top_features['feature'].tolist())
    
    fig4 = plot_feature_importance(feature_importance, top_n=15)
    
    fig5 = plot_golden_trajectory(golden_trajectory, normalized_data, golden_mask)
    
    fig6 = plot_golden_trajectory_combined(golden_trajectory, normalized_data, golden_mask, 
                                           features_df_clustered, golden_cluster)
    
    # 7. ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    
    print("\n[Golden Cycle íŠ¹ì„±]")
    golden_features = features_df_clustered[golden_mask][top_features['feature'].tolist()].mean()
    other_features = features_df_clustered[~golden_mask][top_features['feature'].tolist()].mean()
    
    print("\nGolden vs Others ë¹„êµ (ìƒìœ„ 5ê°œ ì¤‘ìš” íŠ¹ì„±):")
    for feat in feature_importance.head(5)['feature'].values:
        g_val = golden_features[feat]
        o_val = other_features[feat]
        diff_pct = ((g_val - o_val) / (np.abs(o_val) + 1e-6)) * 100
        print(f"  {feat}: Golden={g_val:.4f}, Others={o_val:.4f} (ì°¨ì´: {diff_pct:+.1f}%)")
    
    plt.show()
    
    return {
        'normalized_data': normalized_data,
        'features_df': features_df_clustered,
        'model': model,
        'golden_trajectory': golden_trajectory,
        'golden_cluster': golden_cluster,
        'feature_importance': feature_importance
    }

if __name__ == "__main__":
    results = main()
