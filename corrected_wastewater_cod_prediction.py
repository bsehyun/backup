#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì˜¬ë°”ë¥¸ íìˆ˜ ì²˜ë¦¬ í­ê¸°ì¡° COD ì˜ˆì¸¡ ì‹œìŠ¤í…œ
480ê°œ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ì‹¤ì œë¡œ í™œìš©í•˜ëŠ” ë°©ë²•
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.pipeline import Pipeline
import warnings
warnings.filterwarnings('ignore')

# ì‹œê°í™” ì„¤ì •
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['font.size'] = 12

class CorrectedWastewaterCODPredictor:
    """
    ì˜¬ë°”ë¥¸ íìˆ˜ ì²˜ë¦¬ COD ì˜ˆì¸¡ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.best_model = None
        self.feature_importance = None
        self.feature_generator = None
        
    def create_synthetic_data(self, n_samples=160):
        """
        ì‹¤ì œ íìˆ˜ ì²˜ë¦¬ í˜„ì¥ì„ ì‹œë®¬ë ˆì´ì…˜í•œ ë°ì´í„° ìƒì„±
        """
        print("=== íìˆ˜ ì²˜ë¦¬ í˜„ì¥ ë°ì´í„° ìƒì„± ===\n")
        
        np.random.seed(42)
        
        # ì‹œê°„ ì¸ë±ìŠ¤ (3ì´ˆë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘)
        time_index = pd.date_range('2024-01-01', periods=n_samples, freq='3S')
        
        # ê¸°ë³¸ í™˜ê²½ ë³€ìˆ˜ë“¤
        temperature = 25 + 5 * np.sin(np.arange(n_samples) * 2 * np.pi / (24 * 1200)) + np.random.normal(0, 1, n_samples)
        ph = 7.0 + 0.5 * np.sin(np.arange(n_samples) * np.pi / 600) + np.random.normal(0, 0.1, n_samples)
        dissolved_oxygen = 2.0 + 1.0 * np.sin(np.arange(n_samples) * np.pi / 800) + np.random.normal(0, 0.2, n_samples)
        
        # ìœ ì…ëŸ‰ ê´€ë ¨ ë³€ìˆ˜ë“¤
        flow_rate = 1000 + 200 * np.sin(np.arange(n_samples) * np.pi / 1000) + np.random.normal(0, 50, n_samples)
        conductivity = 800 + 100 * np.sin(np.arange(n_samples) * np.pi / 1200) + np.random.normal(0, 20, n_samples)
        
        # ìŠ¬ëŸ¬ì§€ ê´€ë ¨ ë³€ìˆ˜ë“¤
        mlss = 3000 + 500 * np.sin(np.arange(n_samples) * np.pi / 1500) + np.random.normal(0, 100, n_samples)
        sludge_volume = 200 + 50 * np.sin(np.arange(n_samples) * np.pi / 2000) + np.random.normal(0, 10, n_samples)
        
        # ê° í­ê¸°ì¡°ë³„ íŠ¹ì„± (ì•½ê°„ì˜ ì°¨ì´)
        # í­ê¸°ì¡° 1 (ì²« ë²ˆì§¸)
        aeration_tank1_do = dissolved_oxygen + np.random.normal(0, 0.1, n_samples)
        aeration_tank1_temp = temperature + np.random.normal(0, 0.2, n_samples)
        aeration_tank1_ph = ph + np.random.normal(0, 0.05, n_samples)
        
        # í­ê¸°ì¡° 2 (ì¤‘ê°„ - íƒ€ê²Ÿ)
        aeration_tank2_do = dissolved_oxygen + np.random.normal(0, 0.1, n_samples)
        aeration_tank2_temp = temperature + np.random.normal(0, 0.2, n_samples)
        aeration_tank2_ph = ph + np.random.normal(0, 0.05, n_samples)
        
        # í­ê¸°ì¡° 3 (ë§ˆì§€ë§‰)
        aeration_tank3_do = dissolved_oxygen + np.random.normal(0, 0.1, n_samples)
        aeration_tank3_temp = temperature + np.random.normal(0, 0.2, n_samples)
        aeration_tank3_ph = ph + np.random.normal(0, 0.05, n_samples)
        
        # COD ê°’ ìƒì„± (ì‹¤ì œë¡œëŠ” í•˜ë£¨ì— í•œ ë²ˆ ì¸¡ì •)
        base_cod = 150 + 30 * np.sin(np.arange(n_samples) * np.pi / 1000) + np.random.normal(0, 10, n_samples)
        
        cod_tank1 = base_cod + np.random.normal(0, 5, n_samples)
        cod_tank2 = base_cod + np.random.normal(0, 5, n_samples)  # íƒ€ê²Ÿ
        cod_tank3 = base_cod + np.random.normal(0, 5, n_samples)
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        data = pd.DataFrame({
            'timestamp': time_index,
            'temperature': temperature,
            'ph': ph,
            'flow_rate': flow_rate,
            'conductivity': conductivity,
            'mlss': mlss,
            'sludge_volume': sludge_volume,
            
            # í­ê¸°ì¡° 1 ì„¼ì„œ ë°ì´í„°
            'tank1_do': aeration_tank1_do,
            'tank1_temp': aeration_tank1_temp,
            'tank1_ph': aeration_tank1_ph,
            'cod_tank1': cod_tank1,
            
            # í­ê¸°ì¡° 2 ì„¼ì„œ ë°ì´í„° (íƒ€ê²Ÿ)
            'tank2_do': aeration_tank2_do,
            'tank2_temp': aeration_tank2_temp,
            'tank2_ph': aeration_tank2_ph,
            'cod_tank2': cod_tank2,  # ì˜ˆì¸¡ ëŒ€ìƒ
            
            # í­ê¸°ì¡° 3 ì„¼ì„œ ë°ì´í„°
            'tank3_do': aeration_tank3_do,
            'tank3_temp': aeration_tank3_temp,
            'tank3_ph': aeration_tank3_ph,
            'cod_tank3': cod_tank3,
        })
        
        print(f"ìƒì„±ëœ ë°ì´í„° í¬ê¸°: {data.shape}")
        print(f"ì‹œê°„ ë²”ìœ„: {data['timestamp'].min()} ~ {data['timestamp'].max()}")
        print(f"ì´ ë°ì´í„° í¬ì¸íŠ¸: {len(data)}")
        
        return data
    
    def create_480_datapoints(self, data):
        """
        160ê°œ ë°ì´í„°ë¥¼ 480ê°œë¡œ í™•ì¥í•˜ëŠ” ì˜¬ë°”ë¥¸ ë°©ë²•
        ê° ì‹œê°„ì ì—ì„œ 3ê°œì˜ í­ê¸°ì¡°ë¥¼ ê°ê° ë…ë¦½ì ì¸ ë°ì´í„° í¬ì¸íŠ¸ë¡œ ë§Œë“¦
        """
        print("\n=== 480ê°œ ë°ì´í„° í¬ì¸íŠ¸ ìƒì„± ===\n")
        
        # ê° í­ê¸°ì¡°ë¥¼ ë…ë¦½ì ì¸ ë°ì´í„° í¬ì¸íŠ¸ë¡œ ë³€í™˜
        expanded_data = []
        
        for idx, row in data.iterrows():
            # í­ê¸°ì¡° 1 ë°ì´í„° í¬ì¸íŠ¸
            tank1_data = {
                'timestamp': row['timestamp'],
                'tank_id': 1,
                'target_cod': row['cod_tank1'],  # ê° í­ê¸°ì¡°ì˜ CODê°€ íƒ€ê²Ÿ
                'temperature': row['temperature'],
                'ph': row['ph'],
                'flow_rate': row['flow_rate'],
                'conductivity': row['conductivity'],
                'mlss': row['mlss'],
                'sludge_volume': row['sludge_volume'],
                'do': row['tank1_do'],
                'temp': row['tank1_temp'],
                'ph_tank': row['tank1_ph'],
                # ë‹¤ë¥¸ í­ê¸°ì¡°ì˜ ì„¼ì„œ ì •ë³´ (COD ì œì™¸)
                'tank2_do': row['tank2_do'],
                'tank2_temp': row['tank2_temp'],
                'tank2_ph': row['tank2_ph'],
                'tank3_do': row['tank3_do'],
                'tank3_temp': row['tank3_temp'],
                'tank3_ph': row['tank3_ph'],
            }
            expanded_data.append(tank1_data)
            
            # í­ê¸°ì¡° 2 ë°ì´í„° í¬ì¸íŠ¸
            tank2_data = {
                'timestamp': row['timestamp'],
                'tank_id': 2,
                'target_cod': row['cod_tank2'],
                'temperature': row['temperature'],
                'ph': row['ph'],
                'flow_rate': row['flow_rate'],
                'conductivity': row['conductivity'],
                'mlss': row['mlss'],
                'sludge_volume': row['sludge_volume'],
                'do': row['tank2_do'],
                'temp': row['tank2_temp'],
                'ph_tank': row['tank2_ph'],
                # ë‹¤ë¥¸ í­ê¸°ì¡°ì˜ ì„¼ì„œ ì •ë³´ (COD ì œì™¸)
                'tank1_do': row['tank1_do'],
                'tank1_temp': row['tank1_temp'],
                'tank1_ph': row['tank1_ph'],
                'tank3_do': row['tank3_do'],
                'tank3_temp': row['tank3_temp'],
                'tank3_ph': row['tank3_ph'],
            }
            expanded_data.append(tank2_data)
            
            # í­ê¸°ì¡° 3 ë°ì´í„° í¬ì¸íŠ¸
            tank3_data = {
                'timestamp': row['timestamp'],
                'tank_id': 3,
                'target_cod': row['cod_tank3'],
                'temperature': row['temperature'],
                'ph': row['ph'],
                'flow_rate': row['flow_rate'],
                'conductivity': row['conductivity'],
                'mlss': row['mlss'],
                'sludge_volume': row['sludge_volume'],
                'do': row['tank3_do'],
                'temp': row['tank3_temp'],
                'ph_tank': row['tank3_ph'],
                # ë‹¤ë¥¸ í­ê¸°ì¡°ì˜ ì„¼ì„œ ì •ë³´ (COD ì œì™¸)
                'tank1_do': row['tank1_do'],
                'tank1_temp': row['tank1_temp'],
                'tank1_ph': row['tank1_ph'],
                'tank2_do': row['tank2_do'],
                'tank2_temp': row['tank2_temp'],
                'tank2_ph': row['tank2_ph'],
            }
            expanded_data.append(tank3_data)
        
        expanded_df = pd.DataFrame(expanded_data)
        
        print(f"í™•ì¥ëœ ë°ì´í„° í¬ê¸°: {expanded_df.shape}")
        print(f"ì‹¤ì œ ë°ì´í„° í¬ì¸íŠ¸: {len(expanded_df)}")
        print(f"í­ê¸°ì¡°ë³„ ë°ì´í„° ë¶„í¬:")
        print(expanded_df['tank_id'].value_counts().sort_index())
        
        return expanded_df
    
    def auto_generate_features(self, data):
        """
        ìë™í™”ëœ íŠ¹ì„± ìƒì„± ì‹œìŠ¤í…œ
        """
        print("\n=== ìë™í™”ëœ íŠ¹ì„± ìƒì„± ===\n")
        
        # ê¸°ë³¸ íŠ¹ì„±ë“¤ (ìë™ìœ¼ë¡œ ì°¾ê¸°)
        base_features = ['temperature', 'ph', 'flow_rate', 'conductivity', 'mlss', 'sludge_volume']
        tank_features = ['do', 'temp', 'ph_tank']
        other_tank_features = [col for col in data.columns if col.startswith('tank') and col != 'tank_id']
        
        # ì‹œê°„ ê´€ë ¨ íŠ¹ì„± ìë™ ìƒì„±
        data['hour'] = data['timestamp'].dt.hour
        data['day_of_week'] = data['timestamp'].dt.dayofweek
        data['month'] = data['timestamp'].dt.month
        
        # ì£¼ê¸°ì  íŠ¹ì„± ìë™ ìƒì„±
        periodic_features = []
        for feature, period in [('hour', 24), ('day_of_week', 7), ('month', 12)]:
            data[f'{feature}_sin'] = np.sin(2 * np.pi * data[feature] / period)
            data[f'{feature}_cos'] = np.cos(2 * np.pi * data[feature] / period)
            periodic_features.extend([f'{feature}_sin', f'{feature}_cos'])
        
        # í­ê¸°ì¡° ê°„ ì°¨ì´ íŠ¹ì„± ìë™ ìƒì„±
        diff_features = []
        for tank_feat in tank_features:
            for other_tank in [1, 2, 3]:
                if other_tank != data['tank_id'].iloc[0]:  # í˜„ì¬ í­ê¸°ì¡°ê°€ ì•„ë‹Œ ê²½ìš°
                    other_col = f'tank{other_tank}_{tank_feat.split("_")[0]}'
                    if other_col in data.columns:
                        diff_col = f'{tank_feat}_diff_tank{other_tank}'
                        data[diff_col] = data[tank_feat] - data[other_col]
                        diff_features.append(diff_col)
        
        # ìƒí˜¸ì‘ìš© íŠ¹ì„± ìë™ ìƒì„±
        interaction_features = []
        for i, feat1 in enumerate(tank_features):
            for feat2 in tank_features[i+1:]:
                interaction_col = f'{feat1}_{feat2}_interaction'
                data[interaction_col] = data[feat1] * data[feat2]
                interaction_features.append(interaction_col)
        
        # í™˜ê²½ ë³€ìˆ˜ì™€ì˜ ìƒí˜¸ì‘ìš©
        for env_feat in base_features:
            for tank_feat in tank_features:
                interaction_col = f'{env_feat}_{tank_feat}_interaction'
                data[interaction_col] = data[env_feat] * data[tank_feat]
                interaction_features.append(interaction_col)
        
        # ì´ë™ í‰ê·  íŠ¹ì„± ìë™ ìƒì„±
        ma_features = []
        for window in [3, 5, 10]:
            for tank_feat in tank_features:
                ma_col = f'{tank_feat}_ma_{window}'
                data[ma_col] = data.groupby('tank_id')[tank_feat].rolling(
                    window=window, min_periods=1).mean().reset_index(0, drop=True)
                ma_features.append(ma_col)
        
        # í‘œì¤€í¸ì°¨ íŠ¹ì„± ìë™ ìƒì„±
        std_features = []
        for window in [3, 5]:
            for tank_feat in tank_features:
                std_col = f'{tank_feat}_std_{window}'
                data[std_col] = data.groupby('tank_id')[tank_feat].rolling(
                    window=window, min_periods=1).std().reset_index(0, drop=True)
                std_features.append(std_col)
        
        # ë¹„ìœ¨ íŠ¹ì„± ìë™ ìƒì„±
        ratio_features = []
        for i, feat1 in enumerate(tank_features):
            for feat2 in tank_features[i+1:]:
                ratio_col = f'{feat1}_{feat2}_ratio'
                data[ratio_col] = data[feat1] / (data[feat2] + 1e-8)
                ratio_features.append(ratio_col)
        
        # ìµœì¢… íŠ¹ì„± ë¦¬ìŠ¤íŠ¸ ìë™ ìƒì„±
        all_features = (base_features + tank_features + other_tank_features + 
                       periodic_features + diff_features + interaction_features + 
                       ma_features + std_features + ratio_features)
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        data[all_features] = data[all_features].fillna(0)
        
        X = data[all_features]
        y = data['target_cod']
        
        print(f"ìë™ ìƒì„±ëœ íŠ¹ì„± ê°œìˆ˜: {len(all_features)}")
        print(f"ì…ë ¥ ë°ì´í„° í¬ê¸°: {X.shape}")
        print(f"íƒ€ê²Ÿ ë°ì´í„° í¬ê¸°: {y.shape}")
        print(f"ì‹¤ì œ ë°ì´í„° í¬ì¸íŠ¸: {len(X)}")
        
        return X, y, all_features
    
    def train_models(self, X, y):
        """
        ë‹¤ì–‘í•œ ëª¨ë¸ í›ˆë ¨ ë° ë¹„êµ
        """
        print("\n=== ëª¨ë¸ í›ˆë ¨ ë° ë¹„êµ ===\n")
        
        # ë°ì´í„° ë¶„í•  (ì‹œê°„ ìˆœì„œ ìœ ì§€)
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
        
        # ëª¨ë¸ ì •ì˜
        models = {
            'Linear Regression': LinearRegression(),
            'Ridge Regression': Ridge(alpha=1.0),
            'Lasso Regression': Lasso(alpha=0.1),
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
            'SVR': SVR(kernel='rbf', C=1.0, gamma='scale')
        }
        
        # ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        results = {}
        
        for name, model in models.items():
            print(f"í›ˆë ¨ ì¤‘: {name}")
            
            # ëª¨ë¸ í›ˆë ¨
            model.fit(X_train, y_train)
            
            # ì˜ˆì¸¡
            y_pred = model.predict(X_test)
            
            # í‰ê°€ ì§€í‘œ
            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            results[name] = {
                'model': model,
                'mse': mse,
                'mae': mae,
                'r2': r2,
                'y_pred': y_pred
            }
            
            print(f"  MSE: {mse:.2f}")
            print(f"  MAE: {mae:.2f}")
            print(f"  RÂ²: {r2:.3f}")
            print()
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        best_model_name = max(results.keys(), key=lambda x: results[x]['r2'])
        self.best_model = results[best_model_name]['model']
        
        print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
        print(f"RÂ² Score: {results[best_model_name]['r2']:.3f}")
        
        return results, X_test, y_test
    
    def analyze_feature_importance(self, X, feature_names):
        """
        íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
        """
        print("\n=== íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ===\n")
        
        if hasattr(self.best_model, 'feature_importances_'):
            importance = self.best_model.feature_importances_
        elif hasattr(self.best_model, 'coef_'):
            importance = np.abs(self.best_model.coef_)
        else:
            print("ì´ ëª¨ë¸ì€ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        feature_importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importance
        }).sort_values('importance', ascending=False)
        
        self.feature_importance = feature_importance_df
        
        print("ìƒìœ„ 15ê°œ ì¤‘ìš” íŠ¹ì„±:")
        print(feature_importance_df.head(15))
        
        return feature_importance_df
    
    def visualize_results(self, data, results, X_test, y_test):
        """
        ê²°ê³¼ ì‹œê°í™”
        """
        print("\n=== ê²°ê³¼ ì‹œê°í™” ===\n")
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ì‹¤ì œ vs ì˜ˆì¸¡ ë¹„êµ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)
        best_model_name = max(results.keys(), key=lambda x: results[x]['r2'])
        y_pred_best = results[best_model_name]['y_pred']
        
        axes[0,0].scatter(y_test, y_pred_best, alpha=0.6)
        axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        axes[0,0].set_xlabel('ì‹¤ì œ COD ê°’')
        axes[0,0].set_ylabel('ì˜ˆì¸¡ COD ê°’')
        axes[0,0].set_title(f'{best_model_name} - ì‹¤ì œ vs ì˜ˆì¸¡')
        axes[0,0].grid(True, alpha=0.3)
        
        # 2. ì‹œê°„ë³„ COD ë³€í™”
        test_indices = X_test.index
        axes[0,1].plot(test_indices, y_test.values, 'o-', label='ì‹¤ì œ', linewidth=2)
        axes[0,1].plot(test_indices, y_pred_best, 's-', label='ì˜ˆì¸¡', linewidth=2)
        axes[0,1].set_xlabel('ì‹œê°„ ì¸ë±ìŠ¤')
        axes[0,1].set_ylabel('COD (mg/L)')
        axes[0,1].set_title('ì‹œê°„ë³„ COD ë³€í™”')
        axes[0,1].legend()
        axes[0,1].grid(True, alpha=0.3)
        
        # 3. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        model_names = list(results.keys())
        r2_scores = [results[name]['r2'] for name in model_names]
        
        bars = axes[0,2].bar(model_names, r2_scores, alpha=0.7)
        axes[0,2].set_ylabel('RÂ² Score')
        axes[0,2].set_title('ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ')
        axes[0,2].tick_params(axis='x', rotation=45)
        axes[0,2].grid(True, alpha=0.3)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í•˜ì´ë¼ì´íŠ¸
        best_idx = np.argmax(r2_scores)
        bars[best_idx].set_color('red')
        
        # 4. íŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 10ê°œ)
        if self.feature_importance is not None:
            top_features = self.feature_importance.head(10)
            axes[1,0].barh(top_features['feature'], top_features['importance'])
            axes[1,0].set_xlabel('ì¤‘ìš”ë„')
            axes[1,0].set_title('ìƒìœ„ 10ê°œ ì¤‘ìš” íŠ¹ì„±')
            axes[1,0].grid(True, alpha=0.3)
        
        # 5. ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬
        residuals = y_test - y_pred_best
        axes[1,1].hist(residuals, bins=20, alpha=0.7, edgecolor='black')
        axes[1,1].axvline(0, color='red', linestyle='--', label='ì˜¤ì°¨ ì—†ìŒ')
        axes[1,1].set_xlabel('ì˜ˆì¸¡ ì˜¤ì°¨')
        axes[1,1].set_ylabel('ë¹ˆë„')
        axes[1,1].set_title('ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬')
        axes[1,1].legend()
        axes[1,1].grid(True, alpha=0.3)
        
        # 6. í­ê¸°ì¡°ë³„ COD ë¶„í¬
        test_data = data.iloc[test_indices]
        tank_data = [test_data[test_data['tank_id'] == i]['target_cod'] for i in [1, 2, 3]]
        axes[1,2].boxplot(tank_data, labels=['í­ê¸°ì¡° 1', 'í­ê¸°ì¡° 2', 'í­ê¸°ì¡° 3'])
        axes[1,2].set_ylabel('COD (mg/L)')
        axes[1,2].set_title('í­ê¸°ì¡°ë³„ COD ë¶„í¬')
        axes[1,2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("=== ì˜¬ë°”ë¥¸ íìˆ˜ ì²˜ë¦¬ COD ì˜ˆì¸¡ ì‹œìŠ¤í…œ ===\n")
    
    # 1. ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
    predictor = CorrectedWastewaterCODPredictor()
    
    # 2. ë°ì´í„° ìƒì„±
    data = predictor.create_synthetic_data(n_samples=160)
    
    # 3. 480ê°œ ë°ì´í„° í¬ì¸íŠ¸ë¡œ í™•ì¥
    expanded_data = predictor.create_480_datapoints(data)
    
    # 4. ìë™í™”ëœ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
    X, y, feature_names = predictor.auto_generate_features(expanded_data)
    
    # 5. ëª¨ë¸ í›ˆë ¨ ë° ë¹„êµ
    results, X_test, y_test = predictor.train_models(X, y)
    
    # 6. íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
    feature_importance = predictor.analyze_feature_importance(X, feature_names)
    
    # 7. ê²°ê³¼ ì‹œê°í™”
    predictor.visualize_results(expanded_data, results, X_test, y_test)
    
    # 8. ê²°ë¡ 
    print("\n=== ê²°ë¡  ===\n")
    print("âœ… ì˜¬ë°”ë¥¸ ì ‘ê·¼ ë°©ì‹:")
    print("   - 160ê°œ ë°ì´í„°ë¥¼ 480ê°œë¡œ ì‹¤ì œ í™•ì¥")
    print("   - ê° í­ê¸°ì¡°ë¥¼ ë…ë¦½ì ì¸ ë°ì´í„° í¬ì¸íŠ¸ë¡œ ì²˜ë¦¬")
    print("   - COD ì •ë³´ëŠ” íƒ€ê²Ÿìœ¼ë¡œë§Œ ì‚¬ìš©, Xì—ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ")
    print("   - ìë™í™”ëœ íŠ¹ì„± ìƒì„± ì‹œìŠ¤í…œ êµ¬í˜„")
    
    print(f"\nğŸ“Š ì‹¤ì œ ë°ì´í„° í™œìš©:")
    print(f"   - ì›ë³¸ ë°ì´í„°: 160ê°œ")
    print(f"   - í™•ì¥ëœ ë°ì´í„°: {len(X)}ê°œ")
    print(f"   - íŠ¹ì„± ê°œìˆ˜: {len(feature_names)}ê°œ")
    
    best_model_name = max(results.keys(), key=lambda x: results[x]['r2'])
    print(f"\nğŸ¯ ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   - ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name}")
    print(f"   - RÂ² Score: {results[best_model_name]['r2']:.3f}")

if __name__ == "__main__":
    main() 