# ì‹œê³„ì—´ ë°ì´í„° EDA (Exploratory Data Analysis) ë„êµ¬

ëŒ€ìš©ëŸ‰ ê³ ì°¨ì› ì‹œê³„ì—´ ë°ì´í„°ì˜ ì²« ë²ˆì§¸ ë°ì´í„° ì„±ì§ˆì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ë„êµ¬ìž…ë‹ˆë‹¤.

## ðŸ“‹ ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [ì£¼ìš” ê¸°ëŠ¥](#ì£¼ìš”-ê¸°ëŠ¥)
- [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
- [ì‚¬ìš©ë²•](#ì‚¬ìš©ë²•)
- [íŒŒì¼ êµ¬ì¡°](#íŒŒì¼-êµ¬ì¡°)
- [ì˜ˆì‹œ](#ì˜ˆì‹œ)
- [API ë¬¸ì„œ](#api-ë¬¸ì„œ)

## ðŸŽ¯ ê°œìš”

ì´ ë„êµ¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤:

- **ëŒ€ìš©ëŸ‰ ì‹œê³„ì—´ ë°ì´í„°**: ìˆ˜ì²œ ê°œì˜ ì‹œì ê³¼ ìˆ˜ë°± ê°œì˜ ë³€ìˆ˜ë¥¼ ê°€ì§„ ë°ì´í„°
- **ê³ ì°¨ì› ë°ì´í„°**: ë³€ìˆ˜ ìˆ˜ê°€ ë§Žì€ ë‹¤ì°¨ì› ì‹œê³„ì—´ ë°ì´í„°
- **ì²« ë²ˆì§¸ ë°ì´í„° ì„±ì§ˆ íŒŒì•…**: ì‹œê³„ì—´ì˜ ì´ˆê¸° ìƒíƒœì™€ íŠ¹ì„±ì„ ì´í•´í•˜ê³ ìž í•  ë•Œ
- **ì²´ê³„ì ì¸ EDA**: ë°˜ë³µ ê°€ëŠ¥í•˜ê³  ì¼ê´€ëœ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

### 1. ì²« ë²ˆì§¸ ì‹œì  ë¶„ì„
- ì²« ë²ˆì§¸ ì‹œì ì˜ í†µê³„ì  íŠ¹ì„± ë¶„ì„
- ë¶„í¬ ì‹œê°í™” (ížˆìŠ¤í† ê·¸ëž¨, ë°•ìŠ¤í”Œë¡¯, Q-Q í”Œë¡¯)
- ì´ìƒì¹˜ íƒì§€ (IQR, Z-score ë°©ë²•)
- ê°’ ë²”ìœ„ë³„ ë¶„ë¥˜ ë° ë¶„ì„

### 2. ì°¨ì› ë¶„ì„
- PCAë¥¼ í†µí•œ ì°¨ì› ì¶•ì†Œ ë¶„ì„
- ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨ ê³„ì‚°
- ì²« ë²ˆì§¸ ì‹œì ì˜ ì£¼ì„±ë¶„ ë¶„ì„
- ì°¨ì› ì¶•ì†Œ íš¨ìœ¨ì„± í‰ê°€

### 3. ë³€ìˆ˜ íŠ¹ì„± ë¶„ì„
- ë³€ìˆ˜ë³„ ê°’ í¬ê¸° ë¶„ë¥˜
- ìƒìœ„/í•˜ìœ„ ê°’ ë³€ìˆ˜ ì‹ë³„
- 0ê°’, ìŒìˆ˜, ì–‘ìˆ˜ ë³€ìˆ˜ ë¶„ë¥˜
- ë³€ìˆ˜ ê·¸ë£¹í™” ë° í´ëŸ¬ìŠ¤í„°ë§

### 4. ì‹œê°„ì  íŒ¨í„´ ë¶„ì„
- ì´ˆê¸° êµ¬ê°„ì˜ ì‹œê³„ì—´ íŠ¹ì„± ë¶„ì„
- íŠ¸ë Œë“œ, ê³„ì ˆì„±, ë³€ë™ì„± íŒ¨í„´ ì‹ë³„
- ìžê¸°ìƒê´€ ë¶„ì„
- ë³€ë™ì„± ë†’ì€ ë³€ìˆ˜ íƒì§€

### 5. ìƒê´€ê´€ê³„ ë¶„ì„
- ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ê³„ì‚°
- ì²« ë²ˆì§¸ ì‹œì ê³¼ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
- ìƒê´€ê´€ê³„ ížˆíŠ¸ë§µ ì‹œê°í™”
- ë†’ì€ ìƒê´€ê´€ê³„ ë³€ìˆ˜ ê·¸ë£¹ ì‹ë³„

### 6. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
- ë¶„ì„ ê²°ê³¼ ìš”ì•½
- ì‹œê°í™” ê²°ê³¼ ì €ìž¥
- JSON ë° í…ìŠ¤íŠ¸ í˜•íƒœì˜ ê²°ê³¼ ì €ìž¥
- ìž¬í˜„ ê°€ëŠ¥í•œ ë¶„ì„ ì›Œí¬í”Œë¡œìš°

## ðŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤

```
pandas>=1.5.0
matplotlib>=3.6.0
seaborn>=0.12.0
scikit-learn>=1.2.0
scipy>=1.10.0
umap-learn>=0.5.3
numpy>=1.24.3
```

## ðŸ“– ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from timeseries_eda import TimeseriesEDA

# 1. ë°ì´í„° ë¡œë“œ
eda = TimeseriesEDA(data_path='your_data.csv')
# ë˜ëŠ”
eda = TimeseriesEDA(df=your_dataframe)

# 2. ì „ì²´ ë¶„ì„ ì‹¤í–‰
eda.run_full_analysis(output_dir='results', save_plots=True)
```

### ë‹¨ê³„ë³„ ë¶„ì„

```python
# 1. ì²« ë²ˆì§¸ ì‹œì  ë¶„ì„
first_stats = eda.analyze_first_timestep(save_plots=True)

# 2. ì°¨ì› ë¶„ì„
eda.analyze_dimensions(save_plots=True)

# 3. ë³€ìˆ˜ íŠ¹ì„± ë¶„ì„
eda.analyze_variable_characteristics()

# 4. ì´ˆê¸° ì‹œê³„ì—´ ë¶„ì„
eda.analyze_initial_timeseries(n_periods=100)

# 5. ìƒê´€ê´€ê³„ ë¶„ì„
eda.analyze_correlations(save_plots=True)

# 6. ë³€ìˆ˜ í´ëŸ¬ìŠ¤í„°ë§
eda.cluster_variables(n_clusters=5)
```

### ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš©

```python
from timeseries_eda_utils import *

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
sample_df = generate_sample_timeseries_data(n_timesteps=1000, n_features=200)

# ë¹ ë¥¸ ê°œìš” í™•ì¸
overview = quick_data_overview(sample_df)

# ì²« ë²ˆì§¸ ì‹œì  ìƒì„¸ ë¶„ì„
first_stats = analyze_first_timestep_detailed(sample_df)

# ë³€ìˆ˜ ê·¸ë£¹ ë¶„ì„
groups = analyze_variable_groups(sample_df, n_groups=5)

# ì´ìƒì¹˜ íƒì§€
outliers = detect_outliers_in_first_timestep(sample_df, method='iqr')

# ì‹œê°„ì  íŒ¨í„´ ë¶„ì„
temporal_patterns = analyze_temporal_patterns(sample_df)

# ì¢…í•© ì‹œê°í™”
create_summary_visualization(sample_df)
```

## ðŸ“ íŒŒì¼ êµ¬ì¡°

```
timeseries_eda/
â”œâ”€â”€ timeseries_eda.py          # ë©”ì¸ EDA í´ëž˜ìŠ¤
â”œâ”€â”€ timeseries_eda_utils.py    # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â”œâ”€â”€ example_usage.py           # ì‚¬ìš© ì˜ˆì‹œ
â”œâ”€â”€ requirements.txt           # í•„ìš”í•œ íŒ¨í‚¤ì§€ ëª©ë¡
â””â”€â”€ README_timeseries_eda.md   # ì´ íŒŒì¼
```

## ðŸŽ¨ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ê¸°ë³¸ ì‚¬ìš©ë²•

```python
# ìƒ˜í”Œ ë°ì´í„° ìƒì„± ë° ë¶„ì„
from timeseries_eda import TimeseriesEDA
from timeseries_eda_utils import generate_sample_timeseries_data

# ë°ì´í„° ìƒì„±
sample_df = generate_sample_timeseries_data(n_timesteps=1000, n_features=200)

# EDA ë¶„ì„
eda = TimeseriesEDA(df=sample_df)
eda.run_full_analysis(output_dir='my_results')
```

### ì˜ˆì‹œ 2: ì‹¤ì œ ë°ì´í„° ë¶„ì„

```python
import pandas as pd
from timeseries_eda import TimeseriesEDA

# ì‹¤ì œ ë°ì´í„° ë¡œë“œ
df = pd.read_csv('your_timeseries_data.csv')

# EDA ë¶„ì„
eda = TimeseriesEDA(df=df)

# ì²« ë²ˆì§¸ ì‹œì  ìƒì„¸ ë¶„ì„
first_stats = eda.analyze_first_timestep_detailed(save_plots=True)

# ì°¨ì› ë¶„ì„ (ê³ ì°¨ì› ë°ì´í„°ì¸ ê²½ìš°)
if df.shape[1] > 100:
    eda.analyze_dimensions(save_plots=True)

# ê²°ê³¼ í™•ì¸
print(f"ì²« ë²ˆì§¸ ì‹œì  í‰ê· : {first_stats['mean']:.4f}")
print(f"ì²« ë²ˆì§¸ ì‹œì  í‘œì¤€íŽ¸ì°¨: {first_stats['std']:.4f}")
```

### ì˜ˆì‹œ 3: ì»¤ìŠ¤í…€ ë¶„ì„

```python
from timeseries_eda_utils import *

# ì»¤ìŠ¤í…€ ë¶„ì„ í•¨ìˆ˜
def custom_analysis(df):
    first_row = df.iloc[0]
    
    # íŠ¹ì • ì¡°ê±´ì— ë§žëŠ” ë³€ìˆ˜ë“¤ ì°¾ê¸°
    high_value_vars = first_row[first_row > first_row.quantile(0.9)]
    low_value_vars = first_row[first_row < first_row.quantile(0.1)]
    
    print(f"ë†’ì€ ê°’ ë³€ìˆ˜: {len(high_value_vars)}ê°œ")
    print(f"ë‚®ì€ ê°’ ë³€ìˆ˜: {len(low_value_vars)}ê°œ")
    
    return high_value_vars, low_value_vars

# ë¶„ì„ ì‹¤í–‰
sample_df = generate_sample_timeseries_data()
high_vars, low_vars = custom_analysis(sample_df)
```

## ðŸ“š API ë¬¸ì„œ

### TimeseriesEDA í´ëž˜ìŠ¤

#### ì´ˆê¸°í™”
```python
TimeseriesEDA(data_path=None, df=None)
```

**ë§¤ê°œë³€ìˆ˜:**
- `data_path` (str): ë°ì´í„° íŒŒì¼ ê²½ë¡œ (.csv, .parquet, .xlsx)
- `df` (pd.DataFrame): ì§ì ‘ ì „ë‹¬ëœ ë°ì´í„°í”„ë ˆìž„

#### ì£¼ìš” ë©”ì„œë“œ

##### analyze_first_timestep()
ì²« ë²ˆì§¸ ì‹œì  ë°ì´í„° ë¶„ì„

**ë§¤ê°œë³€ìˆ˜:**
- `save_plots` (bool): í”Œë¡¯ ì €ìž¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
- `output_dir` (str): ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: 'eda_results')

**ë°˜í™˜ê°’:**
- `dict`: ì²« ë²ˆì§¸ ì‹œì  í†µê³„ ì •ë³´

##### analyze_dimensions()
ì°¨ì› ë¶„ì„ (PCA ë“±)

**ë§¤ê°œë³€ìˆ˜:**
- `save_plots` (bool): í”Œë¡¯ ì €ìž¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
- `output_dir` (str): ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: 'eda_results')

##### analyze_variable_characteristics()
ë³€ìˆ˜ë³„ íŠ¹ì„± ë¶„ì„

**ë°˜í™˜ê°’:**
- `dict`: ë³€ìˆ˜ íŠ¹ì„± ë¶„ì„ ê²°ê³¼

##### analyze_initial_timeseries()
ì´ˆê¸° ì‹œê³„ì—´ êµ¬ê°„ ë¶„ì„

**ë§¤ê°œë³€ìˆ˜:**
- `n_periods` (int): ë¶„ì„í•  ì´ˆê¸° êµ¬ê°„ ê¸¸ì´ (ê¸°ë³¸ê°’: 100)
- `save_plots` (bool): í”Œë¡¯ ì €ìž¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
- `output_dir` (str): ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: 'eda_results')

##### analyze_correlations()
ìƒê´€ê´€ê³„ ë¶„ì„

**ë§¤ê°œë³€ìˆ˜:**
- `save_plots` (bool): í”Œë¡¯ ì €ìž¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
- `output_dir` (str): ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: 'eda_results')

##### cluster_variables()
ë³€ìˆ˜ í´ëŸ¬ìŠ¤í„°ë§

**ë§¤ê°œë³€ìˆ˜:**
- `n_clusters` (int): í´ëŸ¬ìŠ¤í„° ìˆ˜ (ê¸°ë³¸ê°’: 5)
- `save_plots` (bool): í”Œë¡¯ ì €ìž¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
- `output_dir` (str): ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: 'eda_results')

##### run_full_analysis()
ì „ì²´ ë¶„ì„ ì‹¤í–‰

**ë§¤ê°œë³€ìˆ˜:**
- `output_dir` (str): ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: 'eda_results')
- `save_plots` (bool): í”Œë¡¯ ì €ìž¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)

### ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

#### generate_sample_timeseries_data()
ìƒ˜í”Œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±

**ë§¤ê°œë³€ìˆ˜:**
- `n_timesteps` (int): ì‹œê³„ì—´ ê¸¸ì´ (ê¸°ë³¸ê°’: 1000)
- `n_features` (int): ë³€ìˆ˜ ìˆ˜ (ê¸°ë³¸ê°’: 200)
- `noise_level` (float): ë…¸ì´ì¦ˆ ìˆ˜ì¤€ (ê¸°ë³¸ê°’: 0.1)

**ë°˜í™˜ê°’:**
- `pd.DataFrame`: ìƒ˜í”Œ ì‹œê³„ì—´ ë°ì´í„°

#### quick_data_overview()
ë°ì´í„° ë¹ ë¥¸ ê°œìš” í™•ì¸

**ë§¤ê°œë³€ìˆ˜:**
- `df` (pd.DataFrame): ë¶„ì„í•  ë°ì´í„°í”„ë ˆìž„

**ë°˜í™˜ê°’:**
- `dict`: ë°ì´í„° ê°œìš” ì •ë³´

#### analyze_first_timestep_detailed()
ì²« ë²ˆì§¸ ì‹œì  ìƒì„¸ ë¶„ì„

**ë§¤ê°œë³€ìˆ˜:**
- `df` (pd.DataFrame): ë¶„ì„í•  ë°ì´í„°í”„ë ˆìž„
- `save_plots` (bool): í”Œë¡¯ ì €ìž¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
- `output_dir` (str): ì €ìž¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: '.')

**ë°˜í™˜ê°’:**
- `dict`: ìƒì„¸ ë¶„ì„ ê²°ê³¼

## ðŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë¶„ì„

ëŒ€ìš©ëŸ‰ ë°ì´í„°ì˜ ê²½ìš° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤:

```python
# ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„ì„
chunk_size = 10000
for chunk in pd.read_csv('large_data.csv', chunksize=chunk_size):
    # ì²­í¬ë³„ ë¶„ì„
    eda = TimeseriesEDA(df=chunk)
    eda.analyze_first_timestep()
```

### 2. ë³‘ë ¬ ì²˜ë¦¬

ì—¬ëŸ¬ ë°ì´í„°ì…‹ì„ ë™ì‹œì— ë¶„ì„:

```python
from concurrent.futures import ProcessPoolExecutor
import multiprocessing

def analyze_dataset(data_path):
    eda = TimeseriesEDA(data_path=data_path)
    return eda.run_full_analysis()

# ë³‘ë ¬ ì²˜ë¦¬
with ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:
    results = list(executor.map(analyze_dataset, data_paths))
```

### 3. ì»¤ìŠ¤í…€ ì‹œê°í™”

```python
import matplotlib.pyplot as plt

def custom_visualization(df, results):
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # ì²« ë²ˆì§¸ ì‹œì  ë¶„í¬
    axes[0, 0].hist(df.iloc[0].dropna(), bins=50)
    axes[0, 0].set_title('ì²« ë²ˆì§¸ ì‹œì  ë¶„í¬')
    
    # ì‹œê°„ë³„ ë³€í™”
    axes[0, 1].plot(df.index[:100], df.mean(axis=1)[:100])
    axes[0, 1].set_title('ì‹œê°„ë³„ í‰ê·  ë³€í™”')
    
    # ë³€ìˆ˜ë³„ í‘œì¤€íŽ¸ì°¨
    axes[1, 0].bar(range(20), df.std().sort_values(ascending=False).head(20))
    axes[1, 0].set_title('ìƒìœ„ 20ê°œ ë³€ë™ì„± ë³€ìˆ˜')
    
    # ìƒê´€ê´€ê³„ ížˆíŠ¸ë§µ
    corr_matrix = df.corr()
    im = axes[1, 1].imshow(corr_matrix.iloc[:20, :20], cmap='coolwarm')
    axes[1, 1].set_title('ìƒìœ„ 20ê°œ ë³€ìˆ˜ ìƒê´€ê´€ê³„')
    
    plt.colorbar(im, ax=axes[1, 1])
    plt.tight_layout()
    plt.show()
```

## ðŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜**
   - ë°ì´í„°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„
   - ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì œê±°
   - ë°ì´í„° íƒ€ìž… ìµœì í™”

2. **ì‹œê°í™” ì˜¤ë¥˜**
   - í•œê¸€ í°íŠ¸ ì„¤ì • í™•ì¸
   - matplotlib ë°±ì—”ë“œ ì„¤ì •
   - ë””ìŠ¤í”Œë ˆì´ í™˜ê²½ í™•ì¸

3. **íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì˜¤ë¥˜**
   - ê°€ìƒí™˜ê²½ ì‚¬ìš© ê¶Œìž¥
   - íŒ¨í‚¤ì§€ ë²„ì „ í˜¸í™˜ì„± í™•ì¸
   - ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜

### ë””ë²„ê¹… íŒ

```python
# ë””ë²„ê¹… ëª¨ë“œë¡œ ì‹¤í–‰
import logging
logging.basicConfig(level=logging.DEBUG)

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
import psutil
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {psutil.virtual_memory().percent}%")

# ë°ì´í„° í¬ê¸° í™•ì¸
print(f"ë°ì´í„° í¬ê¸°: {df.shape}")
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
```

## ðŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ðŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ðŸ“ž ë¬¸ì˜

ë¬¸ì œê°€ ìžˆê±°ë‚˜ ê°œì„  ì‚¬í•­ì´ ìžˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

**ì°¸ê³ **: ì´ ë„êµ¬ëŠ” Jupyter Notebook í™˜ê²½ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìžˆìœ¼ë©°, ëŒ€í™”í˜• ë¶„ì„ì— ìµœì í™”ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.
