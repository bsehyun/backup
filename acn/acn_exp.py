import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import f, t
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.inspection import partial_dependence
import warnings
warnings.filterwarnings('ignore')

# ê³ ê¸‰ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import SALib
    from SALib.sample import saltelli
    from SALib.analyze import sobol
    SOBOL_AVAILABLE = True
except ImportError:
    SOBOL_AVAILABLE = False
    print("SALibê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install SALibë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

try:
    from statsmodels.stats.anova import anova_lm
    from statsmodels.formula.api import ols
    from statsmodels.stats.outliers_influence import variance_inflation_factor
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False
    print("statsmodelsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install statsmodelsë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

class ACNAdvancedExperiments:
    """
    ACN ì •ì œ ê³µì • ê³ ê¸‰ í†µê³„ ë¶„ì„ í´ë˜ìŠ¤
    - Partial Regression Plot
    - ANOVA ë¶„ì„
    - Sobol ë¯¼ê°ë„ ë¶„ì„
    - RSM (Response Surface Methodology)
    """
    
    def __init__(self, data_path=None, df=None):
        """
        ì´ˆê¸°í™”
        
        Parameters:
        data_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        df: ì´ë¯¸ ë¡œë“œëœ DataFrame
        """
        if df is not None:
            self.df = df.copy()
        elif data_path:
            self.df = pd.read_csv(data_path)
        else:
            raise ValueError("ë°ì´í„° ê²½ë¡œ ë˜ëŠ” DataFrameì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        
        self.scaler = StandardScaler()
        self.X = None
        self.y = None
        self.feature_names = None
        self.model = None
        self.results = {}
        
        print("ACN ê³ ê¸‰ ì‹¤í—˜ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def preprocess_data(self):
        """
        ë°ì´í„° ì „ì²˜ë¦¬
        """
        print("=" * 80)
        print("ë°ì´í„° ì „ì²˜ë¦¬")
        print("=" * 80)
        
        # 1. ìµœì¢… F/R Levelì—ì„œ ë¶„ì„í•œ ë°ì´í„°ë§Œ í•„í„°ë§
        if 'Final_FR' in self.df.columns:
            max_fr_level = self.df['Final_FR'].max()
            self.df = self.df[self.df['Final_FR'] == max_fr_level].copy()
            print(f"ìµœì¢… F/R Level í•„í„°ë§ í›„ ë°ì´í„° í¬ê¸°: {self.df.shape}")
        
        # 2. í’ˆì§ˆê°’ ì •ê·œí™” (spec ê¸°ì¤€)
        quality_columns = ['AN-10_200nm', 'AN-10_225nm', 'AN-10_250nm', 
                          'AN-50_200nm', 'AN-50_225nm', 'AN-50_250nm']
        
        for col in quality_columns:
            if col in self.df.columns:
                # 0ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” (ì‹¤ì œ spec ê°’ì— ë”°ë¼ ì¡°ì • í•„ìš”)
                self.df[f'{col}_normalized'] = self.df[col] - 0
        
        # 3. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì„ íƒ (Yield ì œì™¸)
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        if 'Yield' in numeric_cols:
            numeric_cols.remove('Yield')
        
        # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ ì œì™¸
        numeric_cols = [col for col in numeric_cols if not self.df[col].isnull().all()]
        
        # 4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        self.X = self.df[numeric_cols].fillna(self.df[numeric_cols].median())
        self.y = self.df['Yield'].fillna(self.df['Yield'].median())
        
        # 5. íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        self.X_scaled = self.scaler.fit_transform(self.X)
        self.feature_names = numeric_cols
        
        print(f"ë¶„ì„ ëŒ€ìƒ íŠ¹ì„± ìˆ˜: {len(self.feature_names)}")
        print(f"ë¶„ì„ ëŒ€ìƒ ìƒ˜í”Œ ìˆ˜: {len(self.X)}")
        
        return self.X, self.y
    
    def partial_regression_analysis(self):
        """
        Partial Regression Plot ë¶„ì„
        """
        print("\n" + "=" * 80)
        print("Partial Regression Plot ë¶„ì„")
        print("=" * 80)
        
        if self.X is None or self.y is None:
            print("ë°ì´í„°ê°€ ì „ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. preprocess_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        # ì„ í˜• íšŒê·€ ëª¨ë¸ í›ˆë ¨
        self.model = LinearRegression()
        self.model.fit(self.X_scaled, self.y)
        
        # Partial Regression Plot ìƒì„±
        n_features = min(12, len(self.feature_names))  # ìƒìœ„ 12ê°œ íŠ¹ì„±ë§Œ ë¶„ì„
        top_features = self._get_top_features(n_features)
        
        fig, axes = plt.subplots(3, 4, figsize=(20, 15))
        axes = axes.ravel()
        
        partial_results = {}
        
        for i, feature in enumerate(top_features):
            if i >= 12:
                break
                
            # Partial regression ê³„ì‚°
            partial_x, partial_y = self._calculate_partial_regression(feature)
            
            # ì‚°ì ë„ ê·¸ë¦¬ê¸°
            axes[i].scatter(partial_x, partial_y, alpha=0.6)
            
            # íšŒê·€ì„  ì¶”ê°€
            z = np.polyfit(partial_x, partial_y, 1)
            p = np.poly1d(z)
            axes[i].plot(partial_x, p(partial_x), "r--", alpha=0.8)
            
            # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            corr, p_value = stats.pearsonr(partial_x, partial_y)
            
            axes[i].set_xlabel(f'Partial {feature}')
            axes[i].set_ylabel('Partial Yield')
            axes[i].set_title(f'{feature}\nCorr: {corr:.3f}, p: {p_value:.3f}')
            axes[i].grid(True, alpha=0.3)
            
            partial_results[feature] = {
                'correlation': corr,
                'p_value': p_value,
                'partial_x': partial_x,
                'partial_y': partial_y
            }
        
        # ë¹ˆ subplot ì œê±°
        for i in range(len(top_features), 12):
            fig.delaxes(axes[i])
        
        plt.tight_layout()
        plt.show()
        
        self.results['partial_regression'] = partial_results
        
        # ê²°ê³¼ ìš”ì•½
        print("\nPartial Regression ë¶„ì„ ê²°ê³¼ (ìƒìœ„ 10ê°œ):")
        partial_summary = pd.DataFrame([
            {'feature': feat, 'correlation': result['correlation'], 'p_value': result['p_value']}
            for feat, result in partial_results.items()
        ]).sort_values('correlation', key=abs, ascending=False)
        
        print(partial_summary.head(10).round(4))
        
        return partial_results
    
    def _get_top_features(self, n_features):
        """ìƒìœ„ nê°œ íŠ¹ì„± ì„ íƒ"""
        # ëª¨ë¸ ê³„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ íŠ¹ì„± ì„ íƒ
        if self.model is not None:
            feature_importance = np.abs(self.model.coef_)
            top_indices = np.argsort(feature_importance)[-n_features:][::-1]
            return [self.feature_names[i] for i in top_indices]
        else:
            # ìƒê´€ê´€ê³„ ê¸°ì¤€ìœ¼ë¡œ ì„ íƒ
            correlations = []
            for i, feature in enumerate(self.feature_names):
                corr, _ = stats.pearsonr(self.X.iloc[:, i], self.y)
                correlations.append((feature, abs(corr)))
            
            correlations.sort(key=lambda x: x[1], reverse=True)
            return [feat for feat, _ in correlations[:n_features]]
    
    def _calculate_partial_regression(self, target_feature):
        """Partial regression ê³„ì‚°"""
        target_idx = self.feature_names.index(target_feature)
        
        # ë‹¤ë¥¸ íŠ¹ì„±ë“¤ë¡œ ëª¨ë¸ í›ˆë ¨
        other_features = [i for i in range(len(self.feature_names)) if i != target_idx]
        X_other = self.X_scaled[:, other_features]
        
        # Yieldë¥¼ ë‹¤ë¥¸ íŠ¹ì„±ë“¤ë¡œ ì˜ˆì¸¡
        model_other = LinearRegression()
        model_other.fit(X_other, self.y)
        y_pred_other = model_other.predict(X_other)
        
        # Target íŠ¹ì„±ì„ ë‹¤ë¥¸ íŠ¹ì„±ë“¤ë¡œ ì˜ˆì¸¡
        model_target = LinearRegression()
        model_target.fit(X_other, self.X_scaled[:, target_idx])
        x_pred_other = model_target.predict(X_other)
        
        # Partial residuals ê³„ì‚°
        partial_y = self.y - y_pred_other
        partial_x = self.X_scaled[:, target_idx] - x_pred_other
        
        return partial_x, partial_y
    
    def anova_analysis(self):
        """
        ANOVA ë¶„ì„
        """
        print("\n" + "=" * 80)
        print("ANOVA ë¶„ì„")
        print("=" * 80)
        
        if not STATSMODELS_AVAILABLE:
            print("statsmodelsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ANOVA ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        if self.X is None or self.y is None:
            print("ë°ì´í„°ê°€ ì „ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. preprocess_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        # ìƒìœ„ 10ê°œ íŠ¹ì„±ë§Œ ì„ íƒ
        top_features = self._get_top_features(10)
        
        # OLS ëª¨ë¸ ìƒì„±
        formula = 'Yield ~ ' + ' + '.join(top_features)
        
        # ë°ì´í„° ì¤€ë¹„
        anova_data = self.df[top_features + ['Yield']].copy()
        
        try:
            # OLS ëª¨ë¸ í”¼íŒ…
            model = ols(formula, data=anova_data).fit()
            
            # ANOVA í…Œì´ë¸” ìƒì„±
            anova_table = anova_lm(model, typ=2)
            
            print("ANOVA ë¶„ì„ ê²°ê³¼:")
            print(anova_table.round(4))
            
            # F-í†µê³„ëŸ‰ê³¼ p-value ë¶„ì„
            significant_features = anova_table[anova_table['PR(>F)'] < 0.05].sort_values('F', ascending=False)
            
            print(f"\nìœ ì˜í•œ íŠ¹ì„± (p < 0.05): {len(significant_features)}ê°œ")
            if len(significant_features) > 0:
                print(significant_features[['F', 'PR(>F)']].round(4))
            
            # ëª¨ë¸ ìš”ì•½
            print(f"\nëª¨ë¸ ìš”ì•½:")
            print(f"R-squared: {model.rsquared:.4f}")
            print(f"Adjusted R-squared: {model.rsquared_adj:.4f}")
            print(f"F-statistic: {model.fvalue:.4f}")
            print(f"F p-value: {model.f_pvalue:.4f}")
            
            # VIF (Variance Inflation Factor) ê³„ì‚°
            vif_data = pd.DataFrame()
            vif_data["Feature"] = top_features
            vif_data["VIF"] = [variance_inflation_factor(anova_data[top_features].values, i) 
                              for i in range(len(top_features))]
            
            print(f"\nVIF (Variance Inflation Factor):")
            print(vif_data.sort_values('VIF', ascending=False).round(4))
            
            # ë‹¤ì¤‘ê³µì„ ì„± ê²½ê³ 
            high_vif = vif_data[vif_data['VIF'] > 10]
            if len(high_vif) > 0:
                print(f"\nâš ï¸ ë‹¤ì¤‘ê³µì„ ì„± ê²½ê³ : VIF > 10ì¸ íŠ¹ì„± {len(high_vif)}ê°œ")
                print(high_vif[['Feature', 'VIF']].round(2))
            
            anova_results = {
                'anova_table': anova_table,
                'significant_features': significant_features,
                'model_summary': {
                    'r_squared': model.rsquared,
                    'adj_r_squared': model.rsquared_adj,
                    'f_statistic': model.fvalue,
                    'f_pvalue': model.f_pvalue
                },
                'vif': vif_data,
                'high_vif_features': high_vif
            }
            
            self.results['anova'] = anova_results
            return anova_results
            
        except Exception as e:
            print(f"ANOVA ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def sobol_sensitivity_analysis(self):
        """
        Sobol ë¯¼ê°ë„ ë¶„ì„
        """
        print("\n" + "=" * 80)
        print("Sobol ë¯¼ê°ë„ ë¶„ì„")
        print("=" * 80)
        
        if not SOBOL_AVAILABLE:
            print("SALibê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ Sobol ë¯¼ê°ë„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        if self.X is None or self.y is None:
            print("ë°ì´í„°ê°€ ì „ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. preprocess_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        # ìƒìœ„ 8ê°œ íŠ¹ì„±ë§Œ ì„ íƒ (Sobol ë¶„ì„ì€ ê³„ì‚°ëŸ‰ì´ ë§ìŒ)
        top_features = self._get_top_features(8)
        X_selected = self.X[top_features]
        
        # ë¬¸ì œ ì •ì˜
        problem = {
            'num_vars': len(top_features),
            'names': top_features,
            'bounds': [[X_selected[feat].min(), X_selected[feat].max()] for feat in top_features]
        }
        
        # Saltelli ìƒ˜í”Œë§
        param_values = saltelli.sample(problem, 1000)  # N=1000
        
        print(f"Sobol ìƒ˜í”Œë§ ì™„ë£Œ: {param_values.shape[0]}ê°œ ìƒ˜í”Œ")
        
        # ëª¨ë¸ ì˜ˆì¸¡
        try:
            # ì„ í˜• íšŒê·€ ëª¨ë¸ë¡œ ì˜ˆì¸¡
            model = LinearRegression()
            model.fit(X_selected, self.y)
            Y = model.predict(param_values)
            
            # Sobol ë¶„ì„
            Si = sobol.analyze(problem, Y)
            
            # ê²°ê³¼ ì •ë¦¬
            sobol_results = {
                'first_order': pd.DataFrame({
                    'feature': top_features,
                    'S1': Si['S1'],
                    'S1_conf': Si['S1_conf']
                }).sort_values('S1', ascending=False),
                
                'total_order': pd.DataFrame({
                    'feature': top_features,
                    'ST': Si['ST'],
                    'ST_conf': Si['ST_conf']
                }).sort_values('ST', ascending=False),
                
                'second_order': Si['S2'] if 'S2' in Si else None
            }
            
            print("Sobol ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼:")
            print("\n1ì°¨ ë¯¼ê°ë„ ì§€ìˆ˜ (S1):")
            print(sobol_results['first_order'].round(4))
            
            print("\nì´ ë¯¼ê°ë„ ì§€ìˆ˜ (ST):")
            print(sobol_results['total_order'].round(4))
            
            # ì‹œê°í™”
            self._plot_sobol_results(sobol_results)
            
            self.results['sobol'] = sobol_results
            return sobol_results
            
        except Exception as e:
            print(f"Sobol ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def _plot_sobol_results(self, sobol_results):
        """Sobol ê²°ê³¼ ì‹œê°í™”"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # 1ì°¨ ë¯¼ê°ë„ ì§€ìˆ˜
        first_order = sobol_results['first_order']
        ax1.barh(range(len(first_order)), first_order['S1'])
        ax1.set_yticks(range(len(first_order)))
        ax1.set_yticklabels(first_order['feature'])
        ax1.set_xlabel('1ì°¨ ë¯¼ê°ë„ ì§€ìˆ˜ (S1)')
        ax1.set_title('Sobol 1ì°¨ ë¯¼ê°ë„ ì§€ìˆ˜')
        ax1.grid(True, alpha=0.3)
        
        # ì´ ë¯¼ê°ë„ ì§€ìˆ˜
        total_order = sobol_results['total_order']
        ax2.barh(range(len(total_order)), total_order['ST'])
        ax2.set_yticks(range(len(total_order)))
        ax2.set_yticklabels(total_order['feature'])
        ax2.set_xlabel('ì´ ë¯¼ê°ë„ ì§€ìˆ˜ (ST)')
        ax2.set_title('Sobol ì´ ë¯¼ê°ë„ ì§€ìˆ˜')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def response_surface_methodology(self):
        """
        RSM (Response Surface Methodology) ë¶„ì„
        """
        print("\n" + "=" * 80)
        print("RSM (Response Surface Methodology) ë¶„ì„")
        print("=" * 80)
        
        if self.X is None or self.y is None:
            print("ë°ì´í„°ê°€ ì „ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. preprocess_data()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        # ìƒìœ„ 4ê°œ íŠ¹ì„±ë§Œ ì„ íƒ (RSMì€ ì°¨ì›ì´ ë†’ì•„ì§€ë©´ ë³µì¡í•´ì§)
        top_features = self._get_top_features(4)
        X_selected = self.X[top_features]
        
        print(f"RSM ë¶„ì„ ëŒ€ìƒ íŠ¹ì„±: {top_features}")
        
        # 1ì°¨ ëª¨ë¸ (ì„ í˜•)
        linear_model = LinearRegression()
        linear_model.fit(X_selected, self.y)
        linear_r2 = r2_score(self.y, linear_model.predict(X_selected))
        
        # 2ì°¨ ëª¨ë¸ (ì´ì°¨í•­ í¬í•¨)
        poly_features = PolynomialFeatures(degree=2, include_bias=False)
        X_poly = poly_features.fit_transform(X_selected)
        
        poly_model = LinearRegression()
        poly_model.fit(X_poly, self.y)
        poly_r2 = r2_score(self.y, poly_model.predict(X_poly))
        
        print(f"1ì°¨ ëª¨ë¸ RÂ²: {linear_r2:.4f}")
        print(f"2ì°¨ ëª¨ë¸ RÂ²: {poly_r2:.4f}")
        
        # ëª¨ë¸ ë¹„êµ
        if poly_r2 > linear_r2 + 0.05:  # 2ì°¨ ëª¨ë¸ì´ 5% ì´ìƒ ê°œì„ 
            print("2ì°¨ ëª¨ë¸ì´ ë” ì í•©í•©ë‹ˆë‹¤.")
            best_model = poly_model
            best_features = X_poly
            model_type = "2ì°¨"
        else:
            print("1ì°¨ ëª¨ë¸ì´ ë” ì í•©í•©ë‹ˆë‹¤.")
            best_model = linear_model
            best_features = X_selected
            model_type = "1ì°¨"
        
        # êµì°¨ ê²€ì¦
        cv_scores = cross_val_score(best_model, best_features, self.y, cv=5, scoring='r2')
        print(f"êµì°¨ ê²€ì¦ RÂ² (í‰ê·  Â± í‘œì¤€í¸ì°¨): {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
        
        # ì”ì°¨ ë¶„ì„
        y_pred = best_model.predict(best_features)
        residuals = self.y - y_pred
        
        # RSM ì‹œê°í™”
        self._plot_rsm_results(top_features, X_selected, self.y, y_pred, residuals, model_type)
        
        # ìµœì ì  ì°¾ê¸° (ê°„ë‹¨í•œ ê·¸ë¦¬ë“œ ì„œì¹˜)
        optimal_point = self._find_optimal_point(top_features, best_model, poly_features if model_type == "2ì°¨" else None)
        
        rsm_results = {
            'linear_model': linear_model,
            'poly_model': poly_model,
            'best_model': best_model,
            'model_type': model_type,
            'linear_r2': linear_r2,
            'poly_r2': poly_r2,
            'cv_scores': cv_scores,
            'optimal_point': optimal_point,
            'features': top_features
        }
        
        self.results['rsm'] = rsm_results
        return rsm_results
    
    def _plot_rsm_results(self, features, X, y, y_pred, residuals, model_type):
        """RSM ê²°ê³¼ ì‹œê°í™”"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ì˜ˆì¸¡ vs ì‹¤ì œ
        axes[0, 0].scatter(y, y_pred, alpha=0.6)
        axes[0, 0].plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)
        axes[0, 0].set_xlabel('ì‹¤ì œ Yield')
        axes[0, 0].set_ylabel('ì˜ˆì¸¡ Yield')
        axes[0, 0].set_title(f'ì˜ˆì¸¡ vs ì‹¤ì œ ({model_type} ëª¨ë¸)')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ì”ì°¨ í”Œë¡¯
        axes[0, 1].scatter(y_pred, residuals, alpha=0.6)
        axes[0, 1].axhline(y=0, color='r', linestyle='--')
        axes[0, 1].set_xlabel('ì˜ˆì¸¡ Yield')
        axes[0, 1].set_ylabel('ì”ì°¨')
        axes[0, 1].set_title('ì”ì°¨ í”Œë¡¯')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
        axes[0, 2].hist(residuals, bins=20, alpha=0.7, edgecolor='black')
        axes[0, 2].set_xlabel('ì”ì°¨')
        axes[0, 2].set_ylabel('ë¹ˆë„')
        axes[0, 2].set_title('ì”ì°¨ ë¶„í¬')
        axes[0, 2].grid(True, alpha=0.3)
        
        # 4-6. ê° íŠ¹ì„±ë³„ Yield ê´€ê³„ (ìƒìœ„ 3ê°œ)
        for i in range(min(3, len(features))):
            feature = features[i]
            axes[1, i].scatter(X[feature], y, alpha=0.6, label='ì‹¤ì œ')
            axes[1, i].scatter(X[feature], y_pred, alpha=0.6, label='ì˜ˆì¸¡')
            axes[1, i].set_xlabel(feature)
            axes[1, i].set_ylabel('Yield')
            axes[1, i].set_title(f'{feature} vs Yield')
            axes[1, i].legend()
            axes[1, i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def _find_optimal_point(self, features, model, poly_features=None):
        """ìµœì ì  ì°¾ê¸° (ê°„ë‹¨í•œ ê·¸ë¦¬ë“œ ì„œì¹˜)"""
        print("\nìµœì ì  íƒìƒ‰ ì¤‘...")
        
        # ê° íŠ¹ì„±ì˜ ë²”ìœ„ ì •ì˜
        bounds = []
        for feature in features:
            min_val = self.X[feature].min()
            max_val = self.X[feature].max()
            bounds.append((min_val, max_val))
        
        # ê°„ë‹¨í•œ ê·¸ë¦¬ë“œ ì„œì¹˜ (ê° íŠ¹ì„±ì„ 10ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ”)
        best_yield = -np.inf
        best_point = None
        
        # 2ì°¨ ëª¨ë¸ì¸ ê²½ìš° ë‹¤í•­ì‹ íŠ¹ì„± ë³€í™˜ í•„ìš”
        if poly_features is not None:
            # 2ì°¨ ëª¨ë¸ì˜ ê²½ìš° ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ íƒìƒ‰
            n_samples = 1000
            random_points = []
            for i, (min_val, max_val) in enumerate(bounds):
                random_points.append(np.random.uniform(min_val, max_val, n_samples))
            
            X_test = np.column_stack(random_points)
            X_test_poly = poly_features.transform(X_test)
            y_test = model.predict(X_test_poly)
            
            best_idx = np.argmax(y_test)
            best_point = X_test[best_idx]
            best_yield = y_test[best_idx]
        else:
            # 1ì°¨ ëª¨ë¸ì¸ ê²½ìš°
            n_samples = 1000
            random_points = []
            for i, (min_val, max_val) in enumerate(bounds):
                random_points.append(np.random.uniform(min_val, max_val, n_samples))
            
            X_test = np.column_stack(random_points)
            y_test = model.predict(X_test)
            
            best_idx = np.argmax(y_test)
            best_point = X_test[best_idx]
            best_yield = y_test[best_idx]
        
        optimal_result = {
            'optimal_point': dict(zip(features, best_point)),
            'predicted_yield': best_yield,
            'features': features
        }
        
        print("ìµœì ì  íƒìƒ‰ ê²°ê³¼:")
        for feature, value in optimal_result['optimal_point'].items():
            print(f"  {feature}: {value:.4f}")
        print(f"  ì˜ˆì¸¡ Yield: {best_yield:.4f}")
        
        return optimal_result
    
    def generate_comprehensive_report(self):
        """
        ì¢…í•© ì‹¤í—˜ ë¦¬í¬íŠ¸ ìƒì„±
        """
        print("\n" + "=" * 80)
        print("ì¢…í•© ì‹¤í—˜ ë¦¬í¬íŠ¸ ìƒì„±")
        print("=" * 80)
        
        report = {
            'data_info': {
                'n_samples': len(self.X) if self.X is not None else 0,
                'n_features': len(self.feature_names) if self.feature_names is not None else 0,
                'features': self.feature_names[:10] if self.feature_names else []  # ìƒìœ„ 10ê°œë§Œ
            },
            'experiments': {}
        }
        
        # Partial Regression ê²°ê³¼
        if 'partial_regression' in self.results:
            partial_data = self.results['partial_regression']
            top_partial = sorted(partial_data.items(), key=lambda x: abs(x[1]['correlation']), reverse=True)[:5]
            
            report['experiments']['partial_regression'] = {
                'top_features': [{'feature': feat, 'correlation': result['correlation'], 'p_value': result['p_value']} 
                               for feat, result in top_partial],
                'summary': f"ìƒìœ„ 5ê°œ íŠ¹ì„±ì˜ í‰ê·  ì ˆëŒ“ê°’ ìƒê´€ê³„ìˆ˜: {np.mean([abs(result['correlation']) for _, result in top_partial]):.4f}"
            }
        
        # ANOVA ê²°ê³¼
        if 'anova' in self.results:
            anova_data = self.results['anova']
            report['experiments']['anova'] = {
                'significant_features': len(anova_data['significant_features']),
                'r_squared': anova_data['model_summary']['r_squared'],
                'high_vif_count': len(anova_data['high_vif_features']),
                'summary': f"ìœ ì˜í•œ íŠ¹ì„± {len(anova_data['significant_features'])}ê°œ, RÂ² = {anova_data['model_summary']['r_squared']:.4f}"
            }
        
        # Sobol ê²°ê³¼
        if 'sobol' in self.results:
            sobol_data = self.results['sobol']
            top_sobol = sobol_data['first_order'].head(3)
            
            report['experiments']['sobol'] = {
                'top_sensitive_features': [{'feature': row['feature'], 's1': row['S1'], 'st': row['ST']} 
                                         for _, row in top_sobol.iterrows()],
                'summary': f"ìƒìœ„ 3ê°œ ë¯¼ê° íŠ¹ì„±ì˜ í‰ê·  1ì°¨ ë¯¼ê°ë„: {top_sobol['S1'].mean():.4f}"
            }
        
        # RSM ê²°ê³¼
        if 'rsm' in self.results:
            rsm_data = self.results['rsm']
            report['experiments']['rsm'] = {
                'model_type': rsm_data['model_type'],
                'r_squared': rsm_data['poly_r2'] if rsm_data['model_type'] == '2ì°¨' else rsm_data['linear_r2'],
                'cv_score': rsm_data['cv_scores'].mean(),
                'optimal_yield': rsm_data['optimal_point']['predicted_yield'],
                'summary': f"{rsm_data['model_type']} ëª¨ë¸, RÂ² = {rsm_data['poly_r2'] if rsm_data['model_type'] == '2ì°¨' else rsm_data['linear_r2']:.4f}"
            }
        
        # ë¦¬í¬íŠ¸ ì¶œë ¥
        print("\nğŸ“Š ì¢…í•© ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
        print("-" * 50)
        
        for exp_name, exp_data in report['experiments'].items():
            print(f"\n{exp_name.upper()}:")
            print(f"  {exp_data['summary']}")
        
        # ì£¼ìš” ê¶Œì¥ì‚¬í•­
        print("\nğŸ’¡ ì£¼ìš” ê¶Œì¥ì‚¬í•­:")
        
        if 'partial_regression' in report['experiments']:
            top_feature = report['experiments']['partial_regression']['top_features'][0]['feature']
            print(f"  1. Partial Regressionì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±: {top_feature}")
        
        if 'sobol' in report['experiments']:
            top_sensitive = report['experiments']['sobol']['top_sensitive_features'][0]['feature']
            print(f"  2. Sobol ë¯¼ê°ë„ ë¶„ì„ì—ì„œ ê°€ì¥ ë¯¼ê°í•œ íŠ¹ì„±: {top_sensitive}")
        
        if 'rsm' in report['experiments']:
            optimal_yield = report['experiments']['rsm']['optimal_yield']
            print(f"  3. RSM ìµœì í™”ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ìµœëŒ€ Yield: {optimal_yield:.4f}")
        
        return report

def main_advanced_experiments(data_path=None, df=None):
    """
    ACN ê³ ê¸‰ ì‹¤í—˜ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜
    
    Parameters:
    data_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    df: ì´ë¯¸ ë¡œë“œëœ DataFrame
    
    Returns:
    results: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    # 1. ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = ACNAdvancedExperiments(data_path, df)
    
    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    analyzer.preprocess_data()
    
    # 3. Partial Regression ë¶„ì„
    partial_results = analyzer.partial_regression_analysis()
    
    # 4. ANOVA ë¶„ì„
    anova_results = analyzer.anova_analysis()
    
    # 5. Sobol ë¯¼ê°ë„ ë¶„ì„
    sobol_results = analyzer.sobol_sensitivity_analysis()
    
    # 6. RSM ë¶„ì„
    rsm_results = analyzer.response_surface_methodology()
    
    # 7. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    report = analyzer.generate_comprehensive_report()
    
    return {
        'analyzer': analyzer,
        'partial_regression': partial_results,
        'anova': anova_results,
        'sobol': sobol_results,
        'rsm': rsm_results,
        'report': report
    }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ACN ì •ì œ ê³µì • ê³ ê¸‰ ì‹¤í—˜ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("\nì‚¬ìš©ë²•:")
    print("1. CSV íŒŒì¼ì—ì„œ ë¶„ì„:")
    print("   results = main_advanced_experiments(data_path='your_data.csv')")
    print("\n2. DataFrameì—ì„œ ë¶„ì„:")
    print("   results = main_advanced_experiments(df=your_dataframe)")
    print("\n3. ê²°ê³¼ í™•ì¸:")
    print("   print(results['report']['experiments'])")
    print("\ní•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬:")
    print("   pip install SALib statsmodels")
