{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ACN ì •ì œ ê³µì • Yield ë¶„ì„\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ACN ì •ì œ ê³µì •ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ Input source ëŒ€ë¹„ output ì–‘(Yield)ì— ì˜í–¥ì„ ë¼ì¹˜ëŠ” ì¸ìë¥¼ ì°¾ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ë¶„ì„ ëª©í‘œ\n",
        "1. **Feature Selection**: Yieldì— ì˜í–¥ì„ ì£¼ëŠ” ì£¼ìš” ì¸ì ì‹ë³„\n",
        "2. **ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„**: ê³µì • ë³€ìˆ˜ë“¤ ê°„ì˜ ë³µí•©ì  íŒ¨í„´ íƒì§€\n",
        "\n",
        "## ë°ì´í„° ì»¬ëŸ¼ ì„¤ëª…\n",
        "- **No**: fore run (AN-01ì— ë‚¨ì€ íê¸° ë¬¼ì§ˆ ì¬ì‚¬ìš© íšŸìˆ˜)\n",
        "- **F/R Level**: AN-10 í’ˆì§ˆê°’ ë¶„ì„ ì‹œê¸° (product tankì˜ %)\n",
        "- **LC**: ì œí’ˆì˜ í’ˆì§ˆ\n",
        "- **Source**: íšŒì‚¬ source (0/1 binary)\n",
        "- **AN-50_*nm**: ì›ë£Œì˜ í’ˆì§ˆê°’\n",
        "- **AN-01**: splitter, **AN-20**: condenser\n",
        "- **ë‚˜ë¨¸ì§€**: ì—´ ê´€ë ¨ ë³€ìˆ˜ë“¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def load_and_preprocess_data(data_path=None, df=None):\n",
        "    \"\"\"\n",
        "    ACN ì •ì œ ê³µì • ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "    if df is not None:\n",
        "        data = df.copy()\n",
        "    elif data_path:\n",
        "        data = pd.read_csv(data_path)\n",
        "    else:\n",
        "        raise ValueError(\"ë°ì´í„° ê²½ë¡œ ë˜ëŠ” DataFrameì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"ACN ì •ì œ ê³µì • ë°ì´í„° ì „ì²˜ë¦¬\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ì›ë³¸ ë°ì´í„° í¬ê¸°: {data.shape}\")\n",
        "    \n",
        "    # 1. ìµœì¢… F/R Levelì—ì„œ ë¶„ì„í•œ ë°ì´í„°ë§Œ í•„í„°ë§\n",
        "    if 'Final_FR' in data.columns:\n",
        "        max_fr_level = data['Final_FR'].max()\n",
        "        data = data[data['Final_FR'] == max_fr_level].copy()\n",
        "        print(f\"ìµœì¢… F/R Level í•„í„°ë§ í›„ ë°ì´í„° í¬ê¸°: {data.shape}\")\n",
        "        print(f\"ìµœì¢… F/R Level: {max_fr_level}\")\n",
        "    \n",
        "    # 2. í’ˆì§ˆê°’ ì •ê·œí™” (spec ê¸°ì¤€)\n",
        "    quality_columns = ['AN-10_200nm', 'AN-10_225nm', 'AN-10_250nm', \n",
        "                      'AN-50_200nm', 'AN-50_225nm', 'AN-50_250nm']\n",
        "    \n",
        "    # í’ˆì§ˆê°’ ì •ê·œí™” (ìŒìˆ˜: spec out, ì–‘ìˆ˜: spec in)\n",
        "    for col in quality_columns:\n",
        "        if col in data.columns:\n",
        "            # 0ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™” (ì‹¤ì œ spec ê°’ì— ë”°ë¼ ì¡°ì • í•„ìš”)\n",
        "            data[f'{col}_normalized'] = data[col] - 0  # ì‹¤ì œ spec ê°’ìœ¼ë¡œ ë³€ê²½ í•„ìš”\n",
        "    \n",
        "    # 3. ë°ì´í„° íƒ€ì… ì„¤ì •\n",
        "    if 'Date' in data.columns:\n",
        "        data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
        "    \n",
        "    # ë²”ì£¼í˜• ë³€ìˆ˜\n",
        "    categorical_columns = ['Source', 'IsBubbled', 'IsBothChillerOn']\n",
        "    for col in categorical_columns:\n",
        "        if col in data.columns:\n",
        "            data[col] = data[col].astype('category')\n",
        "    \n",
        "    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜\n",
        "    numeric_columns = [col for col in data.columns if col not in categorical_columns + ['Date']]\n",
        "    for col in numeric_columns:\n",
        "        if col in data.columns:\n",
        "            data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "    \n",
        "    print(f\"ì „ì²˜ë¦¬ ì™„ë£Œ í›„ ë°ì´í„° í¬ê¸°: {data.shape}\")\n",
        "    return data\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ (ì‹¤ì œ ë°ì´í„° ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)\n",
        "# df = load_and_preprocess_data(data_path='your_data.csv')\n",
        "# ë˜ëŠ”\n",
        "# df = load_and_preprocess_data(df=your_dataframe)\n",
        "\n",
        "print(\"ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Selection ë¶„ì„ í•¨ìˆ˜\n",
        "def feature_selection_analysis(df):\n",
        "    \"\"\"\n",
        "    Feature Selection ë¶„ì„\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Feature Selection ë¶„ì„\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    if 'Yield' not in df.columns:\n",
        "        print(\"Yield ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "    \n",
        "    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì„ íƒ (Yield ì œì™¸)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if 'Yield' in numeric_cols:\n",
        "        numeric_cols.remove('Yield')\n",
        "    \n",
        "    # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ ì œì™¸\n",
        "    numeric_cols = [col for col in numeric_cols if not df[col].isnull().all()]\n",
        "    \n",
        "    X = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "    y = df['Yield'].fillna(df['Yield'].median())\n",
        "    \n",
        "    print(f\"ë¶„ì„ ëŒ€ìƒ íŠ¹ì„± ìˆ˜: {len(numeric_cols)}\")\n",
        "    print(f\"ë¶„ì„ ëŒ€ìƒ ìƒ˜í”Œ ìˆ˜: {len(X)}\")\n",
        "    \n",
        "    # 1. ìƒê´€ê´€ê³„ ê¸°ë°˜ Feature Selection\n",
        "    print(\"\\n1. ìƒê´€ê´€ê³„ ê¸°ë°˜ Feature Selection\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    correlations = {}\n",
        "    for col in numeric_cols:\n",
        "        if col in X.columns:\n",
        "            corr_pearson, p_value_pearson = pearsonr(X[col], y)\n",
        "            corr_spearman, p_value_spearman = spearmanr(X[col], y)\n",
        "            correlations[col] = {\n",
        "                'pearson_corr': corr_pearson,\n",
        "                'pearson_pvalue': p_value_pearson,\n",
        "                'spearman_corr': corr_spearman,\n",
        "                'spearman_pvalue': p_value_spearman,\n",
        "                'abs_pearson': abs(corr_pearson),\n",
        "                'abs_spearman': abs(corr_spearman)\n",
        "            }\n",
        "    \n",
        "    # ìƒê´€ê´€ê³„ ê²°ê³¼ ì •ë ¬\n",
        "    corr_df = pd.DataFrame(correlations).T\n",
        "    corr_df = corr_df.sort_values('abs_pearson', ascending=False)\n",
        "    \n",
        "    print(\"Yieldì™€ì˜ ìƒê´€ê´€ê³„ (ìƒìœ„ 15ê°œ):\")\n",
        "    print(corr_df[['pearson_corr', 'pearson_pvalue', 'spearman_corr', 'spearman_pvalue']].head(15).round(4))\n",
        "    \n",
        "    return corr_df\n",
        "\n",
        "print(\"Feature Selection í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„ í•¨ìˆ˜\n",
        "def multivariate_pattern_analysis(df, top_features=None):\n",
        "    \"\"\"\n",
        "    ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    if 'Yield' not in df.columns:\n",
        "        print(\"Yield ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "    \n",
        "    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì„ íƒ (Yield ì œì™¸)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if 'Yield' in numeric_cols:\n",
        "        numeric_cols.remove('Yield')\n",
        "    \n",
        "    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
        "    X = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "    y = df['Yield'].fillna(df['Yield'].median())\n",
        "    \n",
        "    # ìƒìœ„ íŠ¹ì„± ì„ íƒ (ê¸°ë³¸ê°’: ìƒìœ„ 10ê°œ)\n",
        "    if top_features is None:\n",
        "        correlations = []\n",
        "        for col in numeric_cols:\n",
        "            if col in X.columns:\n",
        "                corr, _ = pearsonr(X[col], y)\n",
        "                correlations.append((col, abs(corr)))\n",
        "        \n",
        "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_features = [col for col, _ in correlations[:10]]\n",
        "    \n",
        "    print(f\"ë¶„ì„ ëŒ€ìƒ íŠ¹ì„±: {top_features}\")\n",
        "    \n",
        "    X_selected = X[top_features]\n",
        "    \n",
        "    # ë°ì´í„° í‘œì¤€í™”\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_selected)\n",
        "    \n",
        "    # PCA ë¶„ì„\n",
        "    print(\"\\n1. ì£¼ì„±ë¶„ ë¶„ì„ (PCA)\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    pca = PCA()\n",
        "    pca_result = pca.fit_transform(X_scaled)\n",
        "    \n",
        "    # ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨\n",
        "    explained_variance_ratio = pca.explained_variance_ratio_\n",
        "    cumulative_variance = np.cumsum(explained_variance_ratio)\n",
        "    \n",
        "    print(\"ì£¼ì„±ë¶„ë³„ ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨:\")\n",
        "    for i, (var_ratio, cum_var) in enumerate(zip(explained_variance_ratio, cumulative_variance)):\n",
        "        print(f\"PC{i+1}: {var_ratio:.4f} (ëˆ„ì : {cum_var:.4f})\")\n",
        "    \n",
        "    # 95% ë¶„ì‚°ì„ ì„¤ëª…í•˜ëŠ” ì£¼ì„±ë¶„ ìˆ˜\n",
        "    n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
        "    print(f\"\\n95% ë¶„ì‚°ì„ ì„¤ëª…í•˜ëŠ” ì£¼ì„±ë¶„ ìˆ˜: {n_components_95}\")\n",
        "    \n",
        "    return {\n",
        "        'pca': {\n",
        "            'explained_variance_ratio': explained_variance_ratio,\n",
        "            'cumulative_variance': cumulative_variance,\n",
        "            'n_components_95': n_components_95\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì‹œê°í™” í•¨ìˆ˜\n",
        "def create_visualizations(df, feature_results=None, pattern_results=None):\n",
        "    \"\"\"\n",
        "    ì‹œê°í™” ìƒì„±\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ì‹œê°í™” ìƒì„±\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # 1. Yield ë¶„í¬\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    plt.subplot(2, 2, 1)\n",
        "    if 'Yield' in df.columns:\n",
        "        plt.hist(df['Yield'], bins=30, alpha=0.7, edgecolor='black')\n",
        "        plt.axvline(df['Yield'].median(), color='red', linestyle='--', \n",
        "                   label=f'ì¤‘ê°„ê°’: {df[\"Yield\"].median():.3f}')\n",
        "        plt.xlabel('Yield')\n",
        "        plt.ylabel('ë¹ˆë„')\n",
        "        plt.title('Yield ë¶„í¬')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ\n",
        "    plt.subplot(2, 2, 2)\n",
        "    if 'Yield' in df.columns:\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        if len(numeric_cols) > 1:\n",
        "            # ìƒìœ„ 10ê°œ íŠ¹ì„±ë§Œ ì„ íƒ\n",
        "            if feature_results is not None:\n",
        "                top_features = feature_results.head(10).index.tolist()\n",
        "                if 'Yield' not in top_features:\n",
        "                    top_features.append('Yield')\n",
        "                \n",
        "                corr_subset = df[top_features].corr()\n",
        "                sns.heatmap(corr_subset, annot=True, cmap='coolwarm', center=0, fmt='.3f')\n",
        "                plt.title('ìƒìœ„ íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„')\n",
        "    \n",
        "    # 3. PCA ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨\n",
        "    plt.subplot(2, 2, 3)\n",
        "    if pattern_results and 'pca' in pattern_results:\n",
        "        pca_data = pattern_results['pca']\n",
        "        plt.plot(range(1, len(pca_data['explained_variance_ratio']) + 1), \n",
        "                pca_data['explained_variance_ratio'], 'bo-', label='ê°œë³„')\n",
        "        plt.plot(range(1, len(pca_data['cumulative_variance']) + 1), \n",
        "                pca_data['cumulative_variance'], 'ro-', label='ëˆ„ì ')\n",
        "        plt.xlabel('ì£¼ì„±ë¶„')\n",
        "        plt.ylabel('ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨')\n",
        "        plt.title('PCA ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "    \n",
        "    # 4. ì£¼ìš” íŠ¹ì„±ë³„ Yield ì‚°ì ë„\n",
        "    plt.subplot(2, 2, 4)\n",
        "    if feature_results is not None and 'Yield' in df.columns:\n",
        "        top_feature = feature_results.index[0]  # ê°€ì¥ ìƒê´€ê´€ê³„ê°€ ë†’ì€ íŠ¹ì„±\n",
        "        if top_feature in df.columns:\n",
        "            plt.scatter(df[top_feature], df['Yield'], alpha=0.6)\n",
        "            plt.xlabel(top_feature)\n",
        "            plt.ylabel('Yield')\n",
        "            plt.title(f'{top_feature} vs Yield')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"ì‹œê°í™” í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ë¶„ì„ ì‹¤í–‰\n",
        "\n",
        "ì•„ë˜ ì…€ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì—¬ ACN ì •ì œ ê³µì •ì˜ Yield ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "### 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ\n",
        "ì‹¤ì œ ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ DataFrameì„ ì¤€ë¹„í•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë°ì´í„° ë¡œë“œ (ì‹¤ì œ ë°ì´í„° ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)\n",
        "# ì˜ˆì‹œ 1: CSV íŒŒì¼ì—ì„œ ë¡œë“œ\n",
        "# df = load_and_preprocess_data(data_path='your_data.csv')\n",
        "\n",
        "# ì˜ˆì‹œ 2: DataFrameì—ì„œ ë¡œë“œ\n",
        "# df = load_and_preprocess_data(df=your_dataframe)\n",
        "\n",
        "# ì˜ˆì‹œ 3: ìƒ˜í”Œ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)\n",
        "np.random.seed(42)\n",
        "sample_data = {\n",
        "    'No': np.random.randint(1, 6, 100),\n",
        "    'Date': pd.date_range('2023-01-01', periods=100, freq='D'),\n",
        "    'F/R Level': np.random.uniform(50, 100, 100),\n",
        "    'AN-10_200nm': np.random.normal(0.5, 0.1, 100),\n",
        "    'AN-10_225nm': np.random.normal(0.3, 0.05, 100),\n",
        "    'AN-10_250nm': np.random.normal(0.2, 0.03, 100),\n",
        "    'LC': np.random.uniform(0.8, 1.2, 100),\n",
        "    'Source': np.random.choice([0, 1], 100),\n",
        "    'AN-50_200nm': np.random.normal(0.4, 0.08, 100),\n",
        "    'AN-50_225nm': np.random.normal(0.25, 0.04, 100),\n",
        "    'AN-50_250nm': np.random.normal(0.15, 0.02, 100),\n",
        "    'IsBubbled': np.random.choice([0, 1], 100),\n",
        "    'IsBothChillerOn': np.random.choice([0, 1], 100),\n",
        "    'Input_source': np.random.uniform(100, 200, 100),\n",
        "    'Steam_pressure': np.random.uniform(1, 3, 100),\n",
        "    'AN-01_temp': np.random.uniform(80, 120, 100),\n",
        "    'AN-01_pressure': np.random.uniform(0.5, 2, 100),\n",
        "    'Heating_time_min': np.random.uniform(30, 120, 100),\n",
        "    'Stable_time_min': np.random.uniform(10, 60, 100),\n",
        "    'Product_time_min': np.random.uniform(60, 180, 100),\n",
        "    'CWS_temp': np.random.uniform(20, 40, 100),\n",
        "    'CWS_pressure': np.random.uniform(2, 5, 100),\n",
        "    'CWR_temp': np.random.uniform(15, 35, 100),\n",
        "    'CU-01_curr_temp': np.random.uniform(70, 110, 100),\n",
        "    'Final_FR': np.random.uniform(80, 100, 100),\n",
        "    'Product_Level': np.random.uniform(60, 100, 100),\n",
        "    'AN-01_remain': np.random.uniform(10, 50, 100),\n",
        "    'AN-20_temp': np.random.uniform(25, 45, 100),\n",
        "    'Avg_temp': np.random.uniform(70, 100, 100),\n",
        "    'Yield': np.random.uniform(0.7, 0.95, 100)  # ëª©í‘œ ë³€ìˆ˜\n",
        "}\n",
        "\n",
        "df = load_and_preprocess_data(df=pd.DataFrame(sample_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2ë‹¨ê³„: Feature Selection ë¶„ì„\n",
        "feature_results = feature_selection_analysis(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3ë‹¨ê³„: ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„\n",
        "pattern_results = multivariate_pattern_analysis(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4ë‹¨ê³„: ì‹œê°í™”\n",
        "create_visualizations(df, feature_results, pattern_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5ë‹¨ê³„: ê²°ê³¼ í•´ì„ ë° ê¶Œì¥ì‚¬í•­\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ACN ì •ì œ ê³µì • Yield ë¶„ì„ ê²°ê³¼ ìš”ì•½\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if feature_results is not None:\n",
        "    print(\"\\nğŸ” ì£¼ìš” ì˜í–¥ ì¸ì (ìƒìœ„ 5ê°œ):\")\n",
        "    top_5_features = feature_results.head(5)\n",
        "    for i, (feature, row) in enumerate(top_5_features.iterrows(), 1):\n",
        "        print(f\"{i}. {feature}: ìƒê´€ê³„ìˆ˜ {row['pearson_corr']:.4f} (p-value: {row['pearson_pvalue']:.4f})\")\n",
        "\n",
        "if pattern_results is not None and 'pca' in pattern_results:\n",
        "    pca_data = pattern_results['pca']\n",
        "    print(f\"\\nğŸ“Š PCA ë¶„ì„ ê²°ê³¼:\")\n",
        "    print(f\"- 95% ë¶„ì‚°ì„ ì„¤ëª…í•˜ëŠ” ì£¼ì„±ë¶„ ìˆ˜: {pca_data['n_components_95']}\")\n",
        "    print(f\"- ì²« ë²ˆì§¸ ì£¼ì„±ë¶„ ì„¤ëª… ë¶„ì‚°: {pca_data['explained_variance_ratio'][0]:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ“ˆ Yield í†µê³„:\")\n",
        "if 'Yield' in df.columns:\n",
        "    yield_stats = df['Yield'].describe()\n",
        "    print(f\"- í‰ê· : {yield_stats['mean']:.4f}\")\n",
        "    print(f\"- í‘œì¤€í¸ì°¨: {yield_stats['std']:.4f}\")\n",
        "    print(f\"- ë³€ë™ê³„ìˆ˜: {(yield_stats['std']/yield_stats['mean']*100):.2f}%\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ ê¶Œì¥ì‚¬í•­:\")\n",
        "print(\"1. ìƒìœ„ ì˜í–¥ ì¸ìë“¤ì˜ ëª¨ë‹ˆí„°ë§ ê°•í™”\")\n",
        "print(\"2. ê³ ìƒê´€ê´€ê³„ íŠ¹ì„±ë“¤ì˜ ìµœì  ë²”ìœ„ ì„¤ì •\")\n",
        "print(\"3. ì •ê¸°ì ì¸ ê³µì • ë³€ìˆ˜ ì ê²€ ë° ì¡°ì •\")\n",
        "print(\"4. ì´ìƒì¹˜ íƒì§€ ì‹œìŠ¤í…œ êµ¬ì¶•\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
