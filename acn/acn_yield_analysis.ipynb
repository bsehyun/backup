{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ACN 정제 공정 Yield 분석\n",
        "\n",
        "이 노트북은 ACN 정제 공정의 데이터를 분석하여 Input source 대비 output 양(Yield)에 영향을 끼치는 인자를 찾는 것을 목표로 합니다.\n",
        "\n",
        "## 분석 목표\n",
        "1. **Feature Selection**: Yield에 영향을 주는 주요 인자 식별\n",
        "2. **다변량 패턴 분석**: 공정 변수들 간의 복합적 패턴 탐지\n",
        "\n",
        "## 데이터 컬럼 설명\n",
        "- **No**: fore run (AN-01에 남은 폐기 물질 재사용 횟수)\n",
        "- **F/R Level**: AN-10 품질값 분석 시기 (product tank의 %)\n",
        "- **LC**: 제품의 품질\n",
        "- **Source**: 회사 source (0/1 binary)\n",
        "- **AN-50_*nm**: 원료의 품질값\n",
        "- **AN-01**: splitter, **AN-20**: condenser\n",
        "- **나머지**: 열 관련 변수들\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 한글 폰트 설정 (Windows)\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"라이브러리 로드 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 로드 및 전처리 함수\n",
        "def load_and_preprocess_data(data_path=None, df=None):\n",
        "    \"\"\"\n",
        "    ACN 정제 공정 데이터 로드 및 전처리\n",
        "    \"\"\"\n",
        "    if df is not None:\n",
        "        data = df.copy()\n",
        "    elif data_path:\n",
        "        data = pd.read_csv(data_path)\n",
        "    else:\n",
        "        raise ValueError(\"데이터 경로 또는 DataFrame을 제공해야 합니다.\")\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"ACN 정제 공정 데이터 전처리\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"원본 데이터 크기: {data.shape}\")\n",
        "    \n",
        "    # 1. 최종 F/R Level에서 분석한 데이터만 필터링\n",
        "    if 'Final_FR' in data.columns:\n",
        "        max_fr_level = data['Final_FR'].max()\n",
        "        data = data[data['Final_FR'] == max_fr_level].copy()\n",
        "        print(f\"최종 F/R Level 필터링 후 데이터 크기: {data.shape}\")\n",
        "        print(f\"최종 F/R Level: {max_fr_level}\")\n",
        "    \n",
        "    # 2. 품질값 정규화 (spec 기준)\n",
        "    quality_columns = ['AN-10_200nm', 'AN-10_225nm', 'AN-10_250nm', \n",
        "                      'AN-50_200nm', 'AN-50_225nm', 'AN-50_250nm']\n",
        "    \n",
        "    # 품질값 정규화 (음수: spec out, 양수: spec in)\n",
        "    for col in quality_columns:\n",
        "        if col in data.columns:\n",
        "            # 0을 기준으로 정규화 (실제 spec 값에 따라 조정 필요)\n",
        "            data[f'{col}_normalized'] = data[col] - 0  # 실제 spec 값으로 변경 필요\n",
        "    \n",
        "    # 3. 데이터 타입 설정\n",
        "    if 'Date' in data.columns:\n",
        "        data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
        "    \n",
        "    # 범주형 변수\n",
        "    categorical_columns = ['Source', 'IsBubbled', 'IsBothChillerOn']\n",
        "    for col in categorical_columns:\n",
        "        if col in data.columns:\n",
        "            data[col] = data[col].astype('category')\n",
        "    \n",
        "    # 수치형 변수\n",
        "    numeric_columns = [col for col in data.columns if col not in categorical_columns + ['Date']]\n",
        "    for col in numeric_columns:\n",
        "        if col in data.columns:\n",
        "            data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "    \n",
        "    print(f\"전처리 완료 후 데이터 크기: {data.shape}\")\n",
        "    return data\n",
        "\n",
        "# 데이터 로드 (실제 데이터 경로로 변경하세요)\n",
        "# df = load_and_preprocess_data(data_path='your_data.csv')\n",
        "# 또는\n",
        "# df = load_and_preprocess_data(df=your_dataframe)\n",
        "\n",
        "print(\"데이터 전처리 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Selection 분석 함수\n",
        "def feature_selection_analysis(df):\n",
        "    \"\"\"\n",
        "    Feature Selection 분석\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Feature Selection 분석\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    if 'Yield' not in df.columns:\n",
        "        print(\"Yield 컬럼이 없습니다.\")\n",
        "        return None\n",
        "    \n",
        "    # 수치형 변수만 선택 (Yield 제외)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if 'Yield' in numeric_cols:\n",
        "        numeric_cols.remove('Yield')\n",
        "    \n",
        "    # 결측치가 있는 컬럼 제외\n",
        "    numeric_cols = [col for col in numeric_cols if not df[col].isnull().all()]\n",
        "    \n",
        "    X = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "    y = df['Yield'].fillna(df['Yield'].median())\n",
        "    \n",
        "    print(f\"분석 대상 특성 수: {len(numeric_cols)}\")\n",
        "    print(f\"분석 대상 샘플 수: {len(X)}\")\n",
        "    \n",
        "    # 1. 상관관계 기반 Feature Selection\n",
        "    print(\"\\n1. 상관관계 기반 Feature Selection\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    correlations = {}\n",
        "    for col in numeric_cols:\n",
        "        if col in X.columns:\n",
        "            corr_pearson, p_value_pearson = pearsonr(X[col], y)\n",
        "            corr_spearman, p_value_spearman = spearmanr(X[col], y)\n",
        "            correlations[col] = {\n",
        "                'pearson_corr': corr_pearson,\n",
        "                'pearson_pvalue': p_value_pearson,\n",
        "                'spearman_corr': corr_spearman,\n",
        "                'spearman_pvalue': p_value_spearman,\n",
        "                'abs_pearson': abs(corr_pearson),\n",
        "                'abs_spearman': abs(corr_spearman)\n",
        "            }\n",
        "    \n",
        "    # 상관관계 결과 정렬\n",
        "    corr_df = pd.DataFrame(correlations).T\n",
        "    corr_df = corr_df.sort_values('abs_pearson', ascending=False)\n",
        "    \n",
        "    print(\"Yield와의 상관관계 (상위 15개):\")\n",
        "    print(corr_df[['pearson_corr', 'pearson_pvalue', 'spearman_corr', 'spearman_pvalue']].head(15).round(4))\n",
        "    \n",
        "    return corr_df\n",
        "\n",
        "print(\"Feature Selection 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 다변량 패턴 분석 함수\n",
        "def multivariate_pattern_analysis(df, top_features=None):\n",
        "    \"\"\"\n",
        "    다변량 패턴 분석\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"다변량 패턴 분석\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    if 'Yield' not in df.columns:\n",
        "        print(\"Yield 컬럼이 없습니다.\")\n",
        "        return None\n",
        "    \n",
        "    # 수치형 변수만 선택 (Yield 제외)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if 'Yield' in numeric_cols:\n",
        "        numeric_cols.remove('Yield')\n",
        "    \n",
        "    # 결측치 처리\n",
        "    X = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "    y = df['Yield'].fillna(df['Yield'].median())\n",
        "    \n",
        "    # 상위 특성 선택 (기본값: 상위 10개)\n",
        "    if top_features is None:\n",
        "        correlations = []\n",
        "        for col in numeric_cols:\n",
        "            if col in X.columns:\n",
        "                corr, _ = pearsonr(X[col], y)\n",
        "                correlations.append((col, abs(corr)))\n",
        "        \n",
        "        correlations.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_features = [col for col, _ in correlations[:10]]\n",
        "    \n",
        "    print(f\"분석 대상 특성: {top_features}\")\n",
        "    \n",
        "    X_selected = X[top_features]\n",
        "    \n",
        "    # 데이터 표준화\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_selected)\n",
        "    \n",
        "    # PCA 분석\n",
        "    print(\"\\n1. 주성분 분석 (PCA)\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    pca = PCA()\n",
        "    pca_result = pca.fit_transform(X_scaled)\n",
        "    \n",
        "    # 설명 분산 비율\n",
        "    explained_variance_ratio = pca.explained_variance_ratio_\n",
        "    cumulative_variance = np.cumsum(explained_variance_ratio)\n",
        "    \n",
        "    print(\"주성분별 설명 분산 비율:\")\n",
        "    for i, (var_ratio, cum_var) in enumerate(zip(explained_variance_ratio, cumulative_variance)):\n",
        "        print(f\"PC{i+1}: {var_ratio:.4f} (누적: {cum_var:.4f})\")\n",
        "    \n",
        "    # 95% 분산을 설명하는 주성분 수\n",
        "    n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
        "    print(f\"\\n95% 분산을 설명하는 주성분 수: {n_components_95}\")\n",
        "    \n",
        "    return {\n",
        "        'pca': {\n",
        "            'explained_variance_ratio': explained_variance_ratio,\n",
        "            'cumulative_variance': cumulative_variance,\n",
        "            'n_components_95': n_components_95\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"다변량 패턴 분석 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 시각화 함수\n",
        "def create_visualizations(df, feature_results=None, pattern_results=None):\n",
        "    \"\"\"\n",
        "    시각화 생성\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"시각화 생성\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # 1. Yield 분포\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    plt.subplot(2, 2, 1)\n",
        "    if 'Yield' in df.columns:\n",
        "        plt.hist(df['Yield'], bins=30, alpha=0.7, edgecolor='black')\n",
        "        plt.axvline(df['Yield'].median(), color='red', linestyle='--', \n",
        "                   label=f'중간값: {df[\"Yield\"].median():.3f}')\n",
        "        plt.xlabel('Yield')\n",
        "        plt.ylabel('빈도')\n",
        "        plt.title('Yield 분포')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. 상관관계 히트맵\n",
        "    plt.subplot(2, 2, 2)\n",
        "    if 'Yield' in df.columns:\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        if len(numeric_cols) > 1:\n",
        "            # 상위 10개 특성만 선택\n",
        "            if feature_results is not None:\n",
        "                top_features = feature_results.head(10).index.tolist()\n",
        "                if 'Yield' not in top_features:\n",
        "                    top_features.append('Yield')\n",
        "                \n",
        "                corr_subset = df[top_features].corr()\n",
        "                sns.heatmap(corr_subset, annot=True, cmap='coolwarm', center=0, fmt='.3f')\n",
        "                plt.title('상위 특성 간 상관관계')\n",
        "    \n",
        "    # 3. PCA 설명 분산 비율\n",
        "    plt.subplot(2, 2, 3)\n",
        "    if pattern_results and 'pca' in pattern_results:\n",
        "        pca_data = pattern_results['pca']\n",
        "        plt.plot(range(1, len(pca_data['explained_variance_ratio']) + 1), \n",
        "                pca_data['explained_variance_ratio'], 'bo-', label='개별')\n",
        "        plt.plot(range(1, len(pca_data['cumulative_variance']) + 1), \n",
        "                pca_data['cumulative_variance'], 'ro-', label='누적')\n",
        "        plt.xlabel('주성분')\n",
        "        plt.ylabel('설명 분산 비율')\n",
        "        plt.title('PCA 설명 분산 비율')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "    \n",
        "    # 4. 주요 특성별 Yield 산점도\n",
        "    plt.subplot(2, 2, 4)\n",
        "    if feature_results is not None and 'Yield' in df.columns:\n",
        "        top_feature = feature_results.index[0]  # 가장 상관관계가 높은 특성\n",
        "        if top_feature in df.columns:\n",
        "            plt.scatter(df[top_feature], df['Yield'], alpha=0.6)\n",
        "            plt.xlabel(top_feature)\n",
        "            plt.ylabel('Yield')\n",
        "            plt.title(f'{top_feature} vs Yield')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"시각화 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 분석 실행\n",
        "\n",
        "아래 셀들을 순서대로 실행하여 ACN 정제 공정의 Yield 분석을 수행합니다.\n",
        "\n",
        "### 1단계: 데이터 로드\n",
        "실제 데이터 파일 경로를 입력하거나 DataFrame을 준비하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 로드 (실제 데이터 경로로 변경하세요)\n",
        "# 예시 1: CSV 파일에서 로드\n",
        "# df = load_and_preprocess_data(data_path='your_data.csv')\n",
        "\n",
        "# 예시 2: DataFrame에서 로드\n",
        "# df = load_and_preprocess_data(df=your_dataframe)\n",
        "\n",
        "# 예시 3: 샘플 데이터 생성 (테스트용)\n",
        "np.random.seed(42)\n",
        "sample_data = {\n",
        "    'No': np.random.randint(1, 6, 100),\n",
        "    'Date': pd.date_range('2023-01-01', periods=100, freq='D'),\n",
        "    'F/R Level': np.random.uniform(50, 100, 100),\n",
        "    'AN-10_200nm': np.random.normal(0.5, 0.1, 100),\n",
        "    'AN-10_225nm': np.random.normal(0.3, 0.05, 100),\n",
        "    'AN-10_250nm': np.random.normal(0.2, 0.03, 100),\n",
        "    'LC': np.random.uniform(0.8, 1.2, 100),\n",
        "    'Source': np.random.choice([0, 1], 100),\n",
        "    'AN-50_200nm': np.random.normal(0.4, 0.08, 100),\n",
        "    'AN-50_225nm': np.random.normal(0.25, 0.04, 100),\n",
        "    'AN-50_250nm': np.random.normal(0.15, 0.02, 100),\n",
        "    'IsBubbled': np.random.choice([0, 1], 100),\n",
        "    'IsBothChillerOn': np.random.choice([0, 1], 100),\n",
        "    'Input_source': np.random.uniform(100, 200, 100),\n",
        "    'Steam_pressure': np.random.uniform(1, 3, 100),\n",
        "    'AN-01_temp': np.random.uniform(80, 120, 100),\n",
        "    'AN-01_pressure': np.random.uniform(0.5, 2, 100),\n",
        "    'Heating_time_min': np.random.uniform(30, 120, 100),\n",
        "    'Stable_time_min': np.random.uniform(10, 60, 100),\n",
        "    'Product_time_min': np.random.uniform(60, 180, 100),\n",
        "    'CWS_temp': np.random.uniform(20, 40, 100),\n",
        "    'CWS_pressure': np.random.uniform(2, 5, 100),\n",
        "    'CWR_temp': np.random.uniform(15, 35, 100),\n",
        "    'CU-01_curr_temp': np.random.uniform(70, 110, 100),\n",
        "    'Final_FR': np.random.uniform(80, 100, 100),\n",
        "    'Product_Level': np.random.uniform(60, 100, 100),\n",
        "    'AN-01_remain': np.random.uniform(10, 50, 100),\n",
        "    'AN-20_temp': np.random.uniform(25, 45, 100),\n",
        "    'Avg_temp': np.random.uniform(70, 100, 100),\n",
        "    'Yield': np.random.uniform(0.7, 0.95, 100)  # 목표 변수\n",
        "}\n",
        "\n",
        "df = load_and_preprocess_data(df=pd.DataFrame(sample_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2단계: Feature Selection 분석\n",
        "feature_results = feature_selection_analysis(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3단계: 다변량 패턴 분석\n",
        "pattern_results = multivariate_pattern_analysis(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4단계: 시각화\n",
        "create_visualizations(df, feature_results, pattern_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5단계: 결과 해석 및 권장사항\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ACN 정제 공정 Yield 분석 결과 요약\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if feature_results is not None:\n",
        "    print(\"\\n🔍 주요 영향 인자 (상위 5개):\")\n",
        "    top_5_features = feature_results.head(5)\n",
        "    for i, (feature, row) in enumerate(top_5_features.iterrows(), 1):\n",
        "        print(f\"{i}. {feature}: 상관계수 {row['pearson_corr']:.4f} (p-value: {row['pearson_pvalue']:.4f})\")\n",
        "\n",
        "if pattern_results is not None and 'pca' in pattern_results:\n",
        "    pca_data = pattern_results['pca']\n",
        "    print(f\"\\n📊 PCA 분석 결과:\")\n",
        "    print(f\"- 95% 분산을 설명하는 주성분 수: {pca_data['n_components_95']}\")\n",
        "    print(f\"- 첫 번째 주성분 설명 분산: {pca_data['explained_variance_ratio'][0]:.4f}\")\n",
        "\n",
        "print(f\"\\n📈 Yield 통계:\")\n",
        "if 'Yield' in df.columns:\n",
        "    yield_stats = df['Yield'].describe()\n",
        "    print(f\"- 평균: {yield_stats['mean']:.4f}\")\n",
        "    print(f\"- 표준편차: {yield_stats['std']:.4f}\")\n",
        "    print(f\"- 변동계수: {(yield_stats['std']/yield_stats['mean']*100):.2f}%\")\n",
        "\n",
        "print(f\"\\n💡 권장사항:\")\n",
        "print(\"1. 상위 영향 인자들의 모니터링 강화\")\n",
        "print(\"2. 고상관관계 특성들의 최적 범위 설정\")\n",
        "print(\"3. 정기적인 공정 변수 점검 및 조정\")\n",
        "print(\"4. 이상치 탐지 시스템 구축\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
